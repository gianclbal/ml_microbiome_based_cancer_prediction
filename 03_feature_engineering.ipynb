{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Experiment 2: Feature Engineering**\n",
    "\n",
    "## ***Objectives for this Notebook***\n",
    "* Showcase feature engineering, dimensionality reduction techniques, Pipeline, and different ways to evaluate your models.\n",
    "\n",
    "Machine learning models thrive on good data. But raw data often comes messy and unrefined, holding hidden gems amidst irrelevant clutter. This is where feature engineering comes in to offer valuable insights and enhance our datasets for better model performance.\n",
    "\n",
    "**Feature Engineering** is the process of transforming raw data into features that are suitable for training and deploying machine learning models. Simply, it's about:\n",
    "* Selecting the right features: Choosing the most relevant features that hold predictive power for your target variable. Think carefully, irrelevant features can mislead your model!\n",
    "* Transforming features: Scaling, normalizing, or encoding categorical data to ensure all features play fair in the model's eyes. No one wants features dominating the competition due to unfair advantages!\n",
    "* **Creating new features: Combining existing features or extracting hidden patterns to unlock deeper insights. New features can be like secret weapons for your model!**\n",
    "\n",
    "For this project, we are going to focus on creating new features using algorithms that are also used for another technique called dimensionality reduction.\n",
    "\n",
    "**Dimensionality reduction** is a technique used in machine learning to reduce the number of features in a dataset while preserving its essential information. The goal is to simplify the data and improve computational efficiency, mitigate the curse of dimensionality, and enhance the performance of machine learning models. Because we're not really working with a large dataset, we don't need to implement dimensionality reduction in this notebook. But it's important to know that our gameplan for creating new features is to use dimensionality reduction techniques such as NMF, LDA, and PCA, to extract latent features, and then appending those latent features to our current feature space. The process of capturing of new features is also called **feature extraction**.\n",
    "\n",
    "**Algorithms**:\n",
    "* *Non-Negative Matrix Factorization (NMF)*: NMF is a factorization technique that decomposes a matrix into two non-negative matrices. It is particularly useful for non-negative data, such as images or text, and is often applied in topic modeling and image processing.\n",
    "* *Latent Dirichlet Allocation (LDA)*: LDA is a probabilistic generative model used for topic modeling. It assumes that documents are mixtures of topics and that each word's presence is attributable to one of the document's topics. LDA helps discover the underlying topics in a collection of documents.\n",
    "* *Principal Componentn Analysis (PCA)* finds the simplest \"directions\" in your data that capture the most variation, letting you see the big picture with fewer dimensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.) Loading the dataset and setting parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, PCA # algorithms to extract latent features\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score\n",
    "\n",
    "import random\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "seed_value = 42\n",
    "# Set Python seed\n",
    "random.seed(seed_value)\n",
    "\n",
    "# Set NumPy seed\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Set scikit-learn seed\n",
    "sklearn_random_state = check_random_state(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Simonsiella</th>\n",
       "      <th>Treponema</th>\n",
       "      <th>Campylobacter</th>\n",
       "      <th>Helicobacter</th>\n",
       "      <th>Paracoccus</th>\n",
       "      <th>Comamonas</th>\n",
       "      <th>Pseudomonas</th>\n",
       "      <th>Xanthomonas</th>\n",
       "      <th>Agrobacterium</th>\n",
       "      <th>...</th>\n",
       "      <th>Hungatella</th>\n",
       "      <th>Pseudopropionibacterium</th>\n",
       "      <th>Peptoanaerobacter</th>\n",
       "      <th>Emergencia</th>\n",
       "      <th>Prevotellamassilia</th>\n",
       "      <th>Criibacterium</th>\n",
       "      <th>Fournierella</th>\n",
       "      <th>Negativibacillus</th>\n",
       "      <th>Duodenibacillus</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-CG-5720-01A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.895050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-CN-4741-01A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HNSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-BR-6801-01A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-IG-A3I8-01A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ESCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-L5-A4OT-01A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ESCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>TCGA-CG-5719-01A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>TCGA-CQ-5329-01A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HNSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>TCGA-CQ-7068-01A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HNSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>TCGA-CG-4455-01A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>TCGA-AG-A020-01A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>READ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  Simonsiella  Treponema  Campylobacter  Helicobacter  \\\n",
       "0    TCGA-CG-5720-01A          0.0   0.000000       0.000000      0.895050   \n",
       "1    TCGA-CN-4741-01A          0.0   0.000000       0.010470      0.000000   \n",
       "2    TCGA-BR-6801-01A          0.0   0.000000       0.000000      0.000000   \n",
       "3    TCGA-IG-A3I8-01A          0.0   0.000000       0.000000      0.067717   \n",
       "4    TCGA-L5-A4OT-01A          0.0   0.000000       0.012202      0.000000   \n",
       "..                ...          ...        ...            ...           ...   \n",
       "507  TCGA-CG-5719-01A          0.0   0.000000       0.000000      0.106557   \n",
       "508  TCGA-CQ-5329-01A          0.0   0.175564       0.000000      0.000000   \n",
       "509  TCGA-CQ-7068-01A          0.0   0.335060       0.000000      0.000000   \n",
       "510  TCGA-CG-4455-01A          0.0   0.000000       0.000000      0.000000   \n",
       "511  TCGA-AG-A020-01A          0.0   0.000000       0.000000      0.000000   \n",
       "\n",
       "     Paracoccus  Comamonas  Pseudomonas  Xanthomonas  Agrobacterium  ...  \\\n",
       "0           0.0        0.0     0.000000          0.0            0.0  ...   \n",
       "1           0.0        0.0     0.000000          0.0            0.0  ...   \n",
       "2           0.0        0.0     0.000000          0.0            0.0  ...   \n",
       "3           0.0        0.0     0.000000          0.0            0.0  ...   \n",
       "4           0.0        0.0     0.000000          0.0            0.0  ...   \n",
       "..          ...        ...          ...          ...            ...  ...   \n",
       "507         0.0        0.0     0.000000          0.0            0.0  ...   \n",
       "508         0.0        0.0     0.000000          0.0            0.0  ...   \n",
       "509         0.0        0.0     0.000000          0.0            0.0  ...   \n",
       "510         0.0        0.0     0.014781          0.0            0.0  ...   \n",
       "511         0.0        0.0     0.000000          0.0            0.0  ...   \n",
       "\n",
       "     Hungatella  Pseudopropionibacterium  Peptoanaerobacter  Emergencia  \\\n",
       "0           0.0                      0.0           0.000000         0.0   \n",
       "1           0.0                      0.0           0.000000         0.0   \n",
       "2           0.0                      0.0           0.000000         0.0   \n",
       "3           0.0                      0.0           0.000000         0.0   \n",
       "4           0.0                      0.0           0.000000         0.0   \n",
       "..          ...                      ...                ...         ...   \n",
       "507         0.0                      0.0           0.000000         0.0   \n",
       "508         0.0                      0.0           0.136613         0.0   \n",
       "509         0.0                      0.0           0.011534         0.0   \n",
       "510         0.0                      0.0           0.000000         0.0   \n",
       "511         0.0                      0.0           0.000000         0.0   \n",
       "\n",
       "     Prevotellamassilia  Criibacterium  Fournierella  Negativibacillus  \\\n",
       "0                   0.0            0.0           0.0               0.0   \n",
       "1                   0.0            0.0           0.0               0.0   \n",
       "2                   0.0            0.0           0.0               0.0   \n",
       "3                   0.0            0.0           0.0               0.0   \n",
       "4                   0.0            0.0           0.0               0.0   \n",
       "..                  ...            ...           ...               ...   \n",
       "507                 0.0            0.0           0.0               0.0   \n",
       "508                 0.0            0.0           0.0               0.0   \n",
       "509                 0.0            0.0           0.0               0.0   \n",
       "510                 0.0            0.0           0.0               0.0   \n",
       "511                 0.0            0.0           0.0               0.0   \n",
       "\n",
       "     Duodenibacillus  label  \n",
       "0                0.0   STAD  \n",
       "1                0.0   HNSC  \n",
       "2                0.0   STAD  \n",
       "3                0.0   ESCA  \n",
       "4                0.0   ESCA  \n",
       "..               ...    ...  \n",
       "507              0.0   STAD  \n",
       "508              0.0   HNSC  \n",
       "509              0.0   HNSC  \n",
       "510              0.0   STAD  \n",
       "511              0.0   READ  \n",
       "\n",
       "[512 rows x 133 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microbiome_df = pd.read_csv(\"./dataset/microbiome_preprocessed_files/microbiome_merged_dfs.csv\")\n",
    "microbiome_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"HNSC\", \"STAD\", \"COAD\", \"ESCA\", \"READ\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.) Feature Engineering with Cross Validation and Hyperparameter Grid Search**"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember we talked about feature engineering is about creating new features? Before we can proceed with the classification, we need to create those new latent features.\n",
    "\n",
    "**Latent features** are hidden, underlying characteristics of your data revealed through dimensionality reduction techniques like NMF, LDA, and PCA. They capture significant relationships between your original features but aren't directly observable, acting as compressed representations of the data's essence.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we need to update our data loader so that it incorporates a way to extract these new latent features using dimensionality reduction techniques (NMF, LDA, PCA), and appends these new latent features to our current feature space.\n",
    "\n",
    "When we implement NMF, LDA, and PCA, we will use GridSearchCV to help us determine the best hyperparameters. All of these algorithms accept an `n_component` argument, which means \"Number of components to keep.\" Think of it as how many data points you want these algorithms to extract for you when you run them through the dataset.\n",
    "\n",
    "Here's the gameplan of how we're going to update the Data Loader.\n",
    "\n",
    "1. First, we will need the best hyperparmeters from the first experiment. We will use the best hyperparameters for the Random Forest classifier so we don't need to repeat those steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_validation_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HNSC</td>\n",
       "      <td>gini</td>\n",
       "      <td>21</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>51</td>\n",
       "      <td>0.792271</td>\n",
       "      <td>0.940221</td>\n",
       "      <td>0.845135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STAD</td>\n",
       "      <td>gini</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>0.772232</td>\n",
       "      <td>0.974606</td>\n",
       "      <td>0.833919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COAD</td>\n",
       "      <td>gini</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>101</td>\n",
       "      <td>0.921960</td>\n",
       "      <td>0.952209</td>\n",
       "      <td>0.924366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESCA</td>\n",
       "      <td>entropy</td>\n",
       "      <td>11</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526144</td>\n",
       "      <td>0.787640</td>\n",
       "      <td>0.716555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>READ</td>\n",
       "      <td>gini</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.827371</td>\n",
       "      <td>0.677520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label criterion  max_depth  max_features  min_samples_leaf  \\\n",
       "0  HNSC      gini         21            61                 1   \n",
       "1  STAD      gini         11           101                 1   \n",
       "2  COAD      gini         11            61                 1   \n",
       "3  ESCA   entropy         11            81                 1   \n",
       "4  READ      gini         11            61                 1   \n",
       "\n",
       "   min_samples_split  n_estimators  test_score  mean_train_score  \\\n",
       "0                 42            51    0.792271          0.940221   \n",
       "1                  2           101    0.772232          0.974606   \n",
       "2                 42           101    0.921960          0.952209   \n",
       "3                 22             1    0.526144          0.787640   \n",
       "4                  2             1    0.500000          0.827371   \n",
       "\n",
       "   mean_validation_score  \n",
       "0               0.845135  \n",
       "1               0.833919  \n",
       "2               0.924366  \n",
       "3               0.716555  \n",
       "4               0.677520  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp1_best_hyperparam_report = pd.read_csv(\"./dataset/microbiome_preprocessed_files/exp1_v2_best_hyperparam.csv\")\n",
    "exp1_best_hyperparam_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HNSC', 'STAD', 'COAD', 'ESCA', 'READ']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Second, we need to create the hyperparameter grids. Remember we have different best hyperparameters among the different cancer types. For examples, HNSC's best hyperparameter for criterion is gini, while ESCA is entropy. The code below is to create different hyperparameter grids that incorporates the best hyperparameters from experiment 1 + the new hyperapameter grids for the NMF, LDA, and PCA algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for the dimensionality reduction techniques. These ranges came from the paper.\n",
    "nmf_pca_param_grid = {\n",
    "    \"transformer__n_components\": list(range(4,65)) # In paper, features 4 to 64\n",
    "}\n",
    "\n",
    "lda_param_grid = {\n",
    "    \"transformer__n_components\": list(range(1, len(classes))) # In paper, features 1 to length of class-1\n",
    "}\n",
    "\n",
    "\n",
    "# Function to create hyperparameter grids, remember we used the best hyperparameters for the rf classifier from experiment 1.\n",
    "\n",
    "def create_hyperparameter_grids(report_df, additional_param=None):\n",
    "    \"\"\"\n",
    "    report_df (Dataframe): The report from experiment one/ output of the best_hyperparameter_to_df()\n",
    "    additional_param (Dict): Defaults to none, any additional hyperpameters to add to the hyperparameter grid.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_hyperparamter_grid_by_class = {}\n",
    "\n",
    "    # Read the best hyperparameters from experiment 1\n",
    "    exclude_cols = [\"label\", \"test_score\", \"mean_train_score\", \"mean_validation_score\"] # We don't want these columns to be in our future grid parameters\n",
    "    if report_df is None or report_df.empty:\n",
    "        raise ValueError(\"Report DataFrame is required.\")\n",
    "\n",
    "    for c in report_df.index: \n",
    "        # Choose a row (class) from the report DataFrame\n",
    "        selected_class = report_df.index[c]\n",
    "        # Get the best hyperparameters and remove excluded columns\n",
    "        exp1_best_hyperparameters = report_df.loc[selected_class].drop(exclude_cols).to_dict()\n",
    "\n",
    "        exp1_best_hyperparameters = {f\"{key}\": [value] for key, value in exp1_best_hyperparameters.items()} # The format we want for classifier hyperparameters\n",
    "\n",
    "        if additional_param != None:\n",
    "            # Add the additional parameters\n",
    "            exp1_best_hyperparameters = {f\"rf__{key}\": value for key, value in exp1_best_hyperparameters.items()} #Adjust prefix of hyperparameters\n",
    "            combined_param_grid = {**exp1_best_hyperparameters, **additional_param}\n",
    "            new_hyperparamter_grid_by_class[report_df.loc[selected_class][\"label\"]] = combined_param_grid\n",
    "        else:\n",
    "            new_hyperparamter_grid_by_class[report_df.loc[selected_class][\"label\"]] = exp1_best_hyperparameters\n",
    "\n",
    "    return new_hyperparamter_grid_by_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this function in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HNSC': {'rf__criterion': ['gini'],\n",
       "  'rf__max_depth': [21],\n",
       "  'rf__max_features': [61],\n",
       "  'rf__min_samples_leaf': [1],\n",
       "  'rf__min_samples_split': [42],\n",
       "  'rf__n_estimators': [51],\n",
       "  'transformer__n_components': [1, 2, 3, 4]},\n",
       " 'STAD': {'rf__criterion': ['gini'],\n",
       "  'rf__max_depth': [11],\n",
       "  'rf__max_features': [101],\n",
       "  'rf__min_samples_leaf': [1],\n",
       "  'rf__min_samples_split': [2],\n",
       "  'rf__n_estimators': [101],\n",
       "  'transformer__n_components': [1, 2, 3, 4]},\n",
       " 'COAD': {'rf__criterion': ['gini'],\n",
       "  'rf__max_depth': [11],\n",
       "  'rf__max_features': [61],\n",
       "  'rf__min_samples_leaf': [1],\n",
       "  'rf__min_samples_split': [42],\n",
       "  'rf__n_estimators': [101],\n",
       "  'transformer__n_components': [1, 2, 3, 4]},\n",
       " 'ESCA': {'rf__criterion': ['entropy'],\n",
       "  'rf__max_depth': [11],\n",
       "  'rf__max_features': [81],\n",
       "  'rf__min_samples_leaf': [1],\n",
       "  'rf__min_samples_split': [22],\n",
       "  'rf__n_estimators': [1],\n",
       "  'transformer__n_components': [1, 2, 3, 4]},\n",
       " 'READ': {'rf__criterion': ['gini'],\n",
       "  'rf__max_depth': [11],\n",
       "  'rf__max_features': [61],\n",
       "  'rf__min_samples_leaf': [1],\n",
       "  'rf__min_samples_split': [2],\n",
       "  'rf__n_estimators': [1],\n",
       "  'transformer__n_components': [1, 2, 3, 4]}}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_param_grid = create_hyperparameter_grids(report_df=exp1_best_hyperparam_report, additional_param=lda_param_grid)\n",
    "combined_param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice these prefixes \"rf__\" and \"transformer__\" before the hyperparameter names. The prefixes added to hyperparameter\n",
    "names in GridSearchCV are used to distinguish between different hyperparameters. The prefix is simply the name of the estimator\n",
    "that the hyperparameter is being tuned for. For example, if we are tuning the hyperparameters for Random Forest, then the prefix for those hyperparameters will be \"rf__\", and if we are tuning the hyperparameters for dimensionality reduction techniques (data transformers) then the predix will be \"transformers__\". These prefixes are abritrary, you can name it however you like using Pipeline.\n",
    "\n",
    "**Pipeline** chains the data transformation and the classificiation tasks together into a single, powerful workflow. \n",
    "\n",
    "**Concept and use:**\n",
    "* **Chaining transformations and estimators**: You define a list of steps, each consisting of a transformer (e.g., scaling, encoding) and its corresponding parameters. The transformers pre-process the data, while the final estimator (e.g., classifier, regressor) learns from the transformed data.\n",
    "* **Streamlined workflow**: Instead of calling individual fit and predict methods on each step separately, you simply call them on the Pipeline object, simplifying your code and reducing boilerplate.\n",
    "* **Joint parameter tunin**g: You can optimize hyperparameters for all components in the pipeline simultaneously through grid search or other methods, ensuring all steps work together seamlessly.\n",
    "\n",
    "You will see Pipieline in action in the following function.\n",
    "\n",
    "3. Create a function that will extract the latent features using GridSearchCV, and return those latent features in a dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset(X,y,report_df,algorithm=\"NMF\"):\n",
    "    \"\"\"\n",
    "    X (Dataframe): features\n",
    "    y (Dataframe): targets\n",
    "    hyperparameter (Dataframe): hyperparameter report from experiment 1\n",
    "    algorithm (str): name of algorithm you want to use\n",
    "    \"\"\"\n",
    "\n",
    "    augmented_datasets_dict = {}\n",
    "    \n",
    "    # Create the pipeline object. Here we are chaining the dimensionality reduction step and the classifier step.\n",
    "\n",
    "    algorithms_dict = {\"NMF\": NMF(), \"LDA\": LatentDirichletAllocation(), \"PCA\": PCA()}\n",
    "    pipeline = Pipeline([\n",
    "        ('transformer', algorithms_dict[algorithm]),\n",
    "        ('rf', RandomForestClassifier(random_state=seed_value))\n",
    "    ])\n",
    "\n",
    "    # Create the hyperparameters\n",
    "    combined_param_grid = create_hyperparameter_grids(report_df, lda_param_grid if algorithm==\"LDA\" else nmf_pca_param_grid)\n",
    " \n",
    " \n",
    "    print(f'Using algorithm {algorithm}:')\n",
    "    for i in classes:\n",
    "        print(f\"Class {i}\")\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed_value)\n",
    "\n",
    "        # Create the GridSearchCV object\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=combined_param_grid[i],\n",
    "            cv=cv,\n",
    "            n_jobs=-1,  # Use all available processors\n",
    "        )\n",
    "\n",
    "        # Perform the grid search\n",
    "        print(\"Fitting..\")\n",
    "        grid_search.fit(X, y)\n",
    "\n",
    "        # Print the best hyperparameters\n",
    "        print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # LENGTH OF DATASET SHOULD STAY SIMILAR TO ORIGINAL, but length of features should increase by the best n_components\n",
    "\n",
    "        # Transform the original dataset to get the latent features\n",
    "        latent_features = best_model.named_steps['transformer'].transform(X)\n",
    "        print(f\"Count of new columns/latent features: {len(latent_features.T)}\")\n",
    "\n",
    "        print(f\"Count of columns of original feature set: {len(X.T)}\")\n",
    "\n",
    "        feature_augmented = pd.concat((X, pd.DataFrame(latent_features, index=X.index, columns=[f\"new_feature {str(x)}\" for x in range(1,len(latent_features.T)+1)])), axis=1)\n",
    "        print(f\"Count of columns of augmented feature set: {len(feature_augmented.T)}\")\n",
    "        print(f\"Count of rows of augmented dataset: {len(feature_augmented)}\")\n",
    "\n",
    "        augmented_datasets_dict[i] = feature_augmented\n",
    "\n",
    "    return augmented_datasets_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this function in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = [\"name\", \"label\"]\n",
    "features = microbiome_df.drop(columns=exclude_cols)\n",
    "target = microbiome_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using algorithm LDA:\n",
      "Class HNSC\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 21, 'rf__max_features': 61, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 42, 'rf__n_estimators': 51, 'transformer__n_components': 4}\n",
      "Count of new columns/latent features: 4\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 135\n",
      "Count of rows of augmented dataset: 512\n",
      "Class STAD\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 11, 'rf__max_features': 101, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 101, 'transformer__n_components': 4}\n",
      "Count of new columns/latent features: 4\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 135\n",
      "Count of rows of augmented dataset: 512\n",
      "Class COAD\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 11, 'rf__max_features': 61, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 42, 'rf__n_estimators': 101, 'transformer__n_components': 2}\n",
      "Count of new columns/latent features: 2\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 133\n",
      "Count of rows of augmented dataset: 512\n",
      "Class ESCA\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'entropy', 'rf__max_depth': 11, 'rf__max_features': 81, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 22, 'rf__n_estimators': 1, 'transformer__n_components': 4}\n",
      "Count of new columns/latent features: 4\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 135\n",
      "Count of rows of augmented dataset: 512\n",
      "Class READ\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 11, 'rf__max_features': 61, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 1, 'transformer__n_components': 4}\n",
      "Count of new columns/latent features: 4\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 135\n",
      "Count of rows of augmented dataset: 512\n"
     ]
    }
   ],
   "source": [
    "augmented_features_dict = augment_dataset(features, target, exp1_best_hyperparam_report, algorithm=\"LDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect the new augmented dataframe for each class you can run `augmented_features_dict[\"class\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Simonsiella</th>\n",
       "      <th>Treponema</th>\n",
       "      <th>Campylobacter</th>\n",
       "      <th>Helicobacter</th>\n",
       "      <th>Paracoccus</th>\n",
       "      <th>Comamonas</th>\n",
       "      <th>Pseudomonas</th>\n",
       "      <th>Xanthomonas</th>\n",
       "      <th>Agrobacterium</th>\n",
       "      <th>Bradyrhizobium</th>\n",
       "      <th>...</th>\n",
       "      <th>Emergencia</th>\n",
       "      <th>Prevotellamassilia</th>\n",
       "      <th>Criibacterium</th>\n",
       "      <th>Fournierella</th>\n",
       "      <th>Negativibacillus</th>\n",
       "      <th>Duodenibacillus</th>\n",
       "      <th>new_feature 1</th>\n",
       "      <th>new_feature 2</th>\n",
       "      <th>new_feature 3</th>\n",
       "      <th>new_feature 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.895050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125962</td>\n",
       "      <td>0.578220</td>\n",
       "      <td>0.163312</td>\n",
       "      <td>0.132506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127568</td>\n",
       "      <td>0.126969</td>\n",
       "      <td>0.149422</td>\n",
       "      <td>0.596041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128184</td>\n",
       "      <td>0.389527</td>\n",
       "      <td>0.349302</td>\n",
       "      <td>0.132987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128625</td>\n",
       "      <td>0.162140</td>\n",
       "      <td>0.524899</td>\n",
       "      <td>0.184336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128596</td>\n",
       "      <td>0.127785</td>\n",
       "      <td>0.127860</td>\n",
       "      <td>0.615759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128075</td>\n",
       "      <td>0.182294</td>\n",
       "      <td>0.540840</td>\n",
       "      <td>0.148791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129370</td>\n",
       "      <td>0.129261</td>\n",
       "      <td>0.129411</td>\n",
       "      <td>0.611958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128242</td>\n",
       "      <td>0.128137</td>\n",
       "      <td>0.128474</td>\n",
       "      <td>0.615147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131356</td>\n",
       "      <td>0.139573</td>\n",
       "      <td>0.142337</td>\n",
       "      <td>0.586734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.565137</td>\n",
       "      <td>0.136234</td>\n",
       "      <td>0.143811</td>\n",
       "      <td>0.154818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows Ã— 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Simonsiella  Treponema  Campylobacter  Helicobacter  Paracoccus  \\\n",
       "0            0.0   0.000000       0.000000      0.895050         0.0   \n",
       "1            0.0   0.000000       0.010470      0.000000         0.0   \n",
       "2            0.0   0.000000       0.000000      0.000000         0.0   \n",
       "3            0.0   0.000000       0.000000      0.067717         0.0   \n",
       "4            0.0   0.000000       0.012202      0.000000         0.0   \n",
       "..           ...        ...            ...           ...         ...   \n",
       "507          0.0   0.000000       0.000000      0.106557         0.0   \n",
       "508          0.0   0.175564       0.000000      0.000000         0.0   \n",
       "509          0.0   0.335060       0.000000      0.000000         0.0   \n",
       "510          0.0   0.000000       0.000000      0.000000         0.0   \n",
       "511          0.0   0.000000       0.000000      0.000000         0.0   \n",
       "\n",
       "     Comamonas  Pseudomonas  Xanthomonas  Agrobacterium  Bradyrhizobium  ...  \\\n",
       "0          0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "1          0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "2          0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "3          0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "4          0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "..         ...          ...          ...            ...             ...  ...   \n",
       "507        0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "508        0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "509        0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "510        0.0     0.014781          0.0            0.0             0.0  ...   \n",
       "511        0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "\n",
       "     Emergencia  Prevotellamassilia  Criibacterium  Fournierella  \\\n",
       "0           0.0                 0.0            0.0           0.0   \n",
       "1           0.0                 0.0            0.0           0.0   \n",
       "2           0.0                 0.0            0.0           0.0   \n",
       "3           0.0                 0.0            0.0           0.0   \n",
       "4           0.0                 0.0            0.0           0.0   \n",
       "..          ...                 ...            ...           ...   \n",
       "507         0.0                 0.0            0.0           0.0   \n",
       "508         0.0                 0.0            0.0           0.0   \n",
       "509         0.0                 0.0            0.0           0.0   \n",
       "510         0.0                 0.0            0.0           0.0   \n",
       "511         0.0                 0.0            0.0           0.0   \n",
       "\n",
       "     Negativibacillus  Duodenibacillus  new_feature 1  new_feature 2  \\\n",
       "0                 0.0              0.0       0.125962       0.578220   \n",
       "1                 0.0              0.0       0.127568       0.126969   \n",
       "2                 0.0              0.0       0.128184       0.389527   \n",
       "3                 0.0              0.0       0.128625       0.162140   \n",
       "4                 0.0              0.0       0.128596       0.127785   \n",
       "..                ...              ...            ...            ...   \n",
       "507               0.0              0.0       0.128075       0.182294   \n",
       "508               0.0              0.0       0.129370       0.129261   \n",
       "509               0.0              0.0       0.128242       0.128137   \n",
       "510               0.0              0.0       0.131356       0.139573   \n",
       "511               0.0              0.0       0.565137       0.136234   \n",
       "\n",
       "     new_feature 3  new_feature 4  \n",
       "0         0.163312       0.132506  \n",
       "1         0.149422       0.596041  \n",
       "2         0.349302       0.132987  \n",
       "3         0.524899       0.184336  \n",
       "4         0.127860       0.615759  \n",
       "..             ...            ...  \n",
       "507       0.540840       0.148791  \n",
       "508       0.129411       0.611958  \n",
       "509       0.128474       0.615147  \n",
       "510       0.142337       0.586734  \n",
       "511       0.143811       0.154818  \n",
       "\n",
       "[512 rows x 135 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_features_dict[\"HNSC\"] # scroll to the last columns to see the new features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.) Creating a data loader**\n",
    "\n",
    "Now we have our new augmented datasets, we can finally create our data loader! This data loader is similar to experiment 1, the only addition is that it runs the feature engineering functions we have in the 2nd section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_2_data_loader(dataframe, \n",
    "                         label_column, \n",
    "                         classes, \n",
    "                         report_df, \n",
    "                         algorithm=\"NMF\", \n",
    "                         train_test=True):\n",
    "    \"\"\"\n",
    "\n",
    "    Returns:\n",
    "    - dataset_dict: a dictionary where the keys is the targeted class and the values are its corresponding features and labels\n",
    "    \"\"\"\n",
    "    augmented_dataset_dict = {}\n",
    "\n",
    "    exclude_cols = [\"name\", \"label\"]\n",
    "\n",
    "    feat = dataframe.drop(columns=exclude_cols)\n",
    "    tar = dataframe[\"label\"]\n",
    "\n",
    "    # print(f\"len of feat: {len(feat)}\")\n",
    "    # print(f\"len of tar: {len(tar)}\")\n",
    "\n",
    "    augmented_features_dict = augment_dataset(feat, tar,report_df, algorithm=algorithm)\n",
    "\n",
    "\n",
    "    # print(f\"Count of rows in original dataset:{len(dataframe)}\")\n",
    "    # print(f\"Count of rows in augmented dataset:{len(feature_augmented)}\")\n",
    "\n",
    "    for i in classes:\n",
    "        positive_class = i\n",
    "        dframe = pd.DataFrame(index=augmented_features_dict[i].index)\n",
    "        dframe[\"name\"] = dataframe[\"name\"]\n",
    "        dframe = pd.concat([dframe, augmented_features_dict[i]], axis=1)\n",
    "        dframe['label'] = [1 if x == positive_class else 0 for x in dataframe[label_column]]\n",
    "        print(dframe.label.value_counts())\n",
    "        X = dframe.drop([\"name\", \"label\"], axis=1)\n",
    "        y = dframe[\"label\"]\n",
    "        if train_test:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=seed_value)\n",
    "            augmented_dataset_dict[positive_class] = {\"train\": (X_train, y_train),\n",
    "                                            \"test\": (X_test, y_test)}\n",
    "        else:\n",
    "            augmented_dataset_dict[positive_class] = {\"feature\": X, \n",
    "                                            \"label\": y}\n",
    "\n",
    "    return augmented_dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have 3 algorithms, we will need to create 3 different data loaders corresponding to each algorithm, i.e. `exp2_datasets_nmf` corresponds to NMF, and so on and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using algorithm NMF:\n",
      "Class HNSC\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 21, 'rf__max_features': 61, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 42, 'rf__n_estimators': 51, 'transformer__n_components': 43}\n",
      "Count of new columns/latent features: 43\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 174\n",
      "Count of rows of augmented dataset: 512\n",
      "Class STAD\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 11, 'rf__max_features': 101, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 101, 'transformer__n_components': 26}\n",
      "Count of new columns/latent features: 26\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 157\n",
      "Count of rows of augmented dataset: 512\n",
      "Class COAD\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 11, 'rf__max_features': 61, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 42, 'rf__n_estimators': 101, 'transformer__n_components': 36}\n",
      "Count of new columns/latent features: 36\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 167\n",
      "Count of rows of augmented dataset: 512\n",
      "Class ESCA\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'entropy', 'rf__max_depth': 11, 'rf__max_features': 81, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 22, 'rf__n_estimators': 1, 'transformer__n_components': 36}\n",
      "Count of new columns/latent features: 36\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 167\n",
      "Count of rows of augmented dataset: 512\n",
      "Class READ\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 11, 'rf__max_features': 61, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 1, 'transformer__n_components': 37}\n",
      "Count of new columns/latent features: 37\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 168\n",
      "Count of rows of augmented dataset: 512\n",
      "label\n",
      "0    357\n",
      "1    155\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    385\n",
      "1    127\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    387\n",
      "1    125\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    452\n",
      "1     60\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    467\n",
      "1     45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "exp2_datasets_nmf = exp_2_data_loader(dataframe=microbiome_df, \n",
    "                                      label_column=\"label\", \n",
    "                                      classes=classes, \n",
    "                                      report_df=exp1_best_hyperparam_report,\n",
    "                                      algorithm=\"NMF\", \n",
    "                                      train_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using algorithm LDA:\n",
      "Class HNSC\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 21, 'rf__max_features': 61, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 42, 'rf__n_estimators': 51, 'transformer__n_components': 4}\n",
      "Count of new columns/latent features: 4\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 135\n",
      "Count of rows of augmented dataset: 512\n",
      "Class STAD\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 11, 'rf__max_features': 101, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 101, 'transformer__n_components': 3}\n",
      "Count of new columns/latent features: 3\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 134\n",
      "Count of rows of augmented dataset: 512\n",
      "Class COAD\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 11, 'rf__max_features': 61, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 42, 'rf__n_estimators': 101, 'transformer__n_components': 4}\n",
      "Count of new columns/latent features: 4\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 135\n",
      "Count of rows of augmented dataset: 512\n",
      "Class ESCA\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'entropy', 'rf__max_depth': 11, 'rf__max_features': 81, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 22, 'rf__n_estimators': 1, 'transformer__n_components': 4}\n",
      "Count of new columns/latent features: 4\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 135\n",
      "Count of rows of augmented dataset: 512\n",
      "Class READ\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 11, 'rf__max_features': 61, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 1, 'transformer__n_components': 3}\n",
      "Count of new columns/latent features: 3\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 134\n",
      "Count of rows of augmented dataset: 512\n",
      "label\n",
      "0    357\n",
      "1    155\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    385\n",
      "1    127\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    387\n",
      "1    125\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    452\n",
      "1     60\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    467\n",
      "1     45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "exp2_datasets_lda = exp_2_data_loader(microbiome_df, \"label\", classes=classes, report_df=exp1_best_hyperparam_report, algorithm=\"LDA\", train_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using algorithm PCA:\n",
      "Class HNSC\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 21, 'rf__max_features': 61, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 42, 'rf__n_estimators': 51, 'transformer__n_components': 45}\n",
      "Count of new columns/latent features: 45\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 176\n",
      "Count of rows of augmented dataset: 512\n",
      "Class STAD\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 11, 'rf__max_features': 101, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 101, 'transformer__n_components': 45}\n",
      "Count of new columns/latent features: 45\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 176\n",
      "Count of rows of augmented dataset: 512\n",
      "Class COAD\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 11, 'rf__max_features': 61, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 42, 'rf__n_estimators': 101, 'transformer__n_components': 45}\n",
      "Count of new columns/latent features: 45\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 176\n",
      "Count of rows of augmented dataset: 512\n",
      "Class ESCA\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'entropy', 'rf__max_depth': 11, 'rf__max_features': 81, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 22, 'rf__n_estimators': 1, 'transformer__n_components': 38}\n",
      "Count of new columns/latent features: 38\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 169\n",
      "Count of rows of augmented dataset: 512\n",
      "Class READ\n",
      "Fitting..\n",
      "Best Hyperparameters: {'rf__criterion': 'gini', 'rf__max_depth': 11, 'rf__max_features': 61, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 1, 'transformer__n_components': 49}\n",
      "Count of new columns/latent features: 49\n",
      "Count of columns of original feature set: 131\n",
      "Count of columns of augmented feature set: 180\n",
      "Count of rows of augmented dataset: 512\n",
      "label\n",
      "0    357\n",
      "1    155\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    385\n",
      "1    127\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    387\n",
      "1    125\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    452\n",
      "1     60\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    467\n",
      "1     45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "exp2_datasets_pca = exp_2_data_loader(microbiome_df, \"label\", classes=classes, report_df=exp1_best_hyperparam_report, algorithm=\"PCA\", train_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check one of the training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Simonsiella</th>\n",
       "      <th>Treponema</th>\n",
       "      <th>Campylobacter</th>\n",
       "      <th>Helicobacter</th>\n",
       "      <th>Paracoccus</th>\n",
       "      <th>Comamonas</th>\n",
       "      <th>Pseudomonas</th>\n",
       "      <th>Xanthomonas</th>\n",
       "      <th>Agrobacterium</th>\n",
       "      <th>Bradyrhizobium</th>\n",
       "      <th>...</th>\n",
       "      <th>new_feature 45</th>\n",
       "      <th>new_feature 46</th>\n",
       "      <th>new_feature 47</th>\n",
       "      <th>new_feature 48</th>\n",
       "      <th>new_feature 49</th>\n",
       "      <th>new_feature 50</th>\n",
       "      <th>new_feature 51</th>\n",
       "      <th>new_feature 52</th>\n",
       "      <th>new_feature 53</th>\n",
       "      <th>new_feature 54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063332</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.023495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.043899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>435 rows Ã— 185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Simonsiella  Treponema  Campylobacter  Helicobacter  Paracoccus  \\\n",
       "155          0.0   0.010944            0.0      0.000000         0.0   \n",
       "414          0.0   0.000000            0.0      0.107591         0.0   \n",
       "172          0.0   0.000000            0.0      0.000000         0.0   \n",
       "367          0.0   0.000000            0.0      0.421787         0.0   \n",
       "462          0.0   0.000000            0.0      0.000000         0.0   \n",
       "..           ...        ...            ...           ...         ...   \n",
       "33           0.0   0.000000            0.0      0.000000         0.0   \n",
       "15           0.0   0.000000            0.0      0.000000         0.0   \n",
       "198          0.0   0.000000            0.0      0.000000         0.0   \n",
       "211          0.0   0.000000            0.0      0.000000         0.0   \n",
       "494          0.0   0.000000            0.0      0.000000         0.0   \n",
       "\n",
       "     Comamonas  Pseudomonas  Xanthomonas  Agrobacterium  Bradyrhizobium  ...  \\\n",
       "155        0.0     0.017489          0.0            0.0             0.0  ...   \n",
       "414        0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "172        0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "367        0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "462        0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "..         ...          ...          ...            ...             ...  ...   \n",
       "33         0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "15         0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "198        0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "211        0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "494        0.0     0.000000          0.0            0.0             0.0  ...   \n",
       "\n",
       "     new_feature 45  new_feature 46  new_feature 47  new_feature 48  \\\n",
       "155        0.000000        0.000000             0.0        0.063332   \n",
       "414        0.000000        0.000000             0.0        0.000000   \n",
       "172        0.002634        0.023495             0.0        0.000000   \n",
       "367        0.000000        0.000000             0.0        0.001253   \n",
       "462        0.000398        0.000000             0.0        0.000000   \n",
       "..              ...             ...             ...             ...   \n",
       "33         0.051051        0.000000             0.0        0.000000   \n",
       "15         0.000000        0.000000             0.0        0.000000   \n",
       "198        0.000000        0.000000             0.0        0.000000   \n",
       "211        0.000000        0.000000             0.0        0.000000   \n",
       "494        0.000000        0.000000             0.0        0.000000   \n",
       "\n",
       "     new_feature 49  new_feature 50  new_feature 51  new_feature 52  \\\n",
       "155        0.000951        0.000000        0.000000        0.000000   \n",
       "414        0.000000        0.000093        0.000000        0.000000   \n",
       "172        0.000000        0.000000        0.005242        0.043899   \n",
       "367        0.000000        0.000000        0.000000        0.000000   \n",
       "462        0.000000        0.000000        0.000000        0.000000   \n",
       "..              ...             ...             ...             ...   \n",
       "33         0.000000        0.000000        0.000000        0.000000   \n",
       "15         0.000000        0.000000        0.000000        0.000000   \n",
       "198        0.000000        0.000068        0.000000        0.000000   \n",
       "211        0.000000        0.000000        0.000112        0.000000   \n",
       "494        0.000002        0.000059        0.000000        0.000000   \n",
       "\n",
       "     new_feature 53  new_feature 54  \n",
       "155             0.0        0.000000  \n",
       "414             0.0        0.000060  \n",
       "172             0.0        0.000000  \n",
       "367             0.0        0.000000  \n",
       "462             0.0        0.000000  \n",
       "..              ...             ...  \n",
       "33              0.0        0.000000  \n",
       "15              0.0        0.000003  \n",
       "198             0.0        0.000050  \n",
       "211             0.0        0.000000  \n",
       "494             0.0        0.000000  \n",
       "\n",
       "[435 rows x 185 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2_datasets_nmf[\"HNSC\"][\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_validation_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HNSC</td>\n",
       "      <td>gini</td>\n",
       "      <td>21</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>51</td>\n",
       "      <td>0.792271</td>\n",
       "      <td>0.940221</td>\n",
       "      <td>0.845135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STAD</td>\n",
       "      <td>gini</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>0.772232</td>\n",
       "      <td>0.974606</td>\n",
       "      <td>0.833919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COAD</td>\n",
       "      <td>gini</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>101</td>\n",
       "      <td>0.921960</td>\n",
       "      <td>0.952209</td>\n",
       "      <td>0.924366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESCA</td>\n",
       "      <td>entropy</td>\n",
       "      <td>11</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526144</td>\n",
       "      <td>0.787640</td>\n",
       "      <td>0.716555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>READ</td>\n",
       "      <td>gini</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.827371</td>\n",
       "      <td>0.677520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label criterion  max_depth  max_features  min_samples_leaf  \\\n",
       "0  HNSC      gini         21            61                 1   \n",
       "1  STAD      gini         11           101                 1   \n",
       "2  COAD      gini         11            61                 1   \n",
       "3  ESCA   entropy         11            81                 1   \n",
       "4  READ      gini         11            61                 1   \n",
       "\n",
       "   min_samples_split  n_estimators  test_score  mean_train_score  \\\n",
       "0                 42            51    0.792271          0.940221   \n",
       "1                  2           101    0.772232          0.974606   \n",
       "2                 42           101    0.921960          0.952209   \n",
       "3                 22             1    0.526144          0.787640   \n",
       "4                  2             1    0.500000          0.827371   \n",
       "\n",
       "   mean_validation_score  \n",
       "0               0.845135  \n",
       "1               0.833919  \n",
       "2               0.924366  \n",
       "3               0.716555  \n",
       "4               0.677520  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp1_best_hyperparam_by_class = create_hyperparameter_grids(exp1_best_hyperparam_report, None)\n",
    "exp1_best_hyperparam_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.) Training with the new features using GridSearchCV**\n",
    "\n",
    "To recap, here's what we've done so far. We've done feature engineering using GridSearch that gave us new augmented datasets. With these augmented datasets, we can now train them. The code below is the same training loop function we have in experiment 1, except that the hyperpameter grids are now created using the create_hyperparameter_grids function, and we added a confusion matrix that tells us what type of errors the models is making.\n",
    "\n",
    "### **A Note on Evaluation**\n",
    "\n",
    "The evaluation portion of the model is incporated in the training function. You can modify the metric you want to use to evaluate the performance of your model by changing the `scoring` argument. We chose \"balanced_accuracy\" because it is the metric that the paper used.\n",
    "\n",
    "`scoring` takes in a str like \"accuracy\" or a list of metrics like F1, precision, or recall. For a list of metrics, visit https://scikit-learn.org/stable/modules/model_evaluation.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_gridsearchcv(dataset_dict, classes, cv_n_splits=5, n_jobs=12):\n",
    "    report = {}\n",
    "    for c in classes:\n",
    "        print(\"Class: \", c)\n",
    "        features = dataset_dict[c][\"train\"][0]\n",
    "        target = dataset_dict[c][\"train\"][1]\n",
    "\n",
    "        # Define the classifier\n",
    "        rf = RandomForestClassifier(random_state=seed_value)\n",
    "\n",
    "        exp1_best_hyperparameter_grids = create_hyperparameter_grids(exp1_best_hyperparam_report, None)\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=cv_n_splits, shuffle=True, random_state=seed_value)\n",
    "\n",
    "        # Create the GridSearchCV object\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=rf,\n",
    "            param_grid=exp1_best_hyperparameter_grids[c],\n",
    "            scoring=make_scorer(balanced_accuracy_score),  # Choose an appropriate metric for your problem\n",
    "            cv=cv,\n",
    "            n_jobs=-1,  # Use all available processors,\n",
    "            return_train_score=True\n",
    ")\n",
    "\n",
    "        # Perform the grid search\n",
    "        grid_search.fit(features, target)\n",
    "\n",
    "        # Access cv_results_ attribute to get detailed results\n",
    "        cv_results = grid_search.cv_results_\n",
    "\n",
    "        # Print the best hyperparameters\n",
    "        print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Evaluate the best model on your test set\n",
    "        predictions = best_model.predict(dataset_dict[c][\"test\"][0])\n",
    "        accuracy = balanced_accuracy_score(dataset_dict[c][\"test\"][1], predictions) \n",
    "        cm = confusion_matrix(dataset_dict[c][\"test\"][1], predictions)\n",
    "        print(f\"Confusion matrix for {c}\")\n",
    "        class_report = classification_report(dataset_dict[c][\"test\"][1], predictions)\n",
    "        # disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=grid_search.classes_)\n",
    "        # disp.plot()\n",
    "        # plt.show\n",
    "        print(\"Accuracy on Test Set:\", accuracy)\n",
    "\n",
    "\n",
    "        # Calculate mean train score and mean test score\n",
    "        mean_train_score = cv_results['mean_train_score'][grid_search.best_index_]\n",
    "        mean_test_score = cv_results['mean_test_score'][grid_search.best_index_]\n",
    "\n",
    "        print(\"Mean Train Score:\", mean_train_score)\n",
    "        print(\"Mean Test Score:\", mean_test_score)\n",
    "\n",
    "\n",
    "        report[c] = {\n",
    "            \"model\": best_model,\n",
    "            \"best_hyperparameters\": grid_search.best_params_,\n",
    "            \"test_score\": accuracy,\n",
    "            \"mean_train_score\": mean_train_score,\n",
    "            \"mean_validation_score\": mean_test_score,\n",
    "            \"confusion_matrix\": cm,\n",
    "            \"classification_report\": class_report\n",
    "        }\n",
    "        \n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  HNSC\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 21, 'max_features': 61, 'min_samples_leaf': 1, 'min_samples_split': 42, 'n_estimators': 51}\n",
      "Confusion matrix for HNSC\n",
      "Accuracy on Test Set: 0.8140096618357487\n",
      "Mean Train Score: 0.9432654973230541\n",
      "Mean Test Score: 0.817882630423614\n",
      "Class:  STAD\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 11, 'max_features': 101, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 101}\n",
      "Confusion matrix for STAD\n",
      "Accuracy on Test Set: 0.7372958257713249\n",
      "Mean Train Score: 0.9780807270783214\n",
      "Mean Test Score: 0.8246120546120548\n",
      "Class:  COAD\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 11, 'max_features': 61, 'min_samples_leaf': 1, 'min_samples_split': 42, 'n_estimators': 101}\n",
      "Confusion matrix for COAD\n",
      "Accuracy on Test Set: 0.8956442831215972\n",
      "Mean Train Score: 0.953363617482942\n",
      "Mean Test Score: 0.9133266733266734\n",
      "Class:  ESCA\n",
      "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 11, 'max_features': 81, 'min_samples_leaf': 1, 'min_samples_split': 22, 'n_estimators': 1}\n",
      "Confusion matrix for ESCA\n",
      "Accuracy on Test Set: 0.6446078431372549\n",
      "Mean Train Score: 0.8013936095683135\n",
      "Mean Test Score: 0.6898974709501025\n",
      "Class:  READ\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 11, 'max_features': 61, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1}\n",
      "Confusion matrix for READ\n",
      "Accuracy on Test Set: 0.5\n",
      "Mean Train Score: 0.8270556092091293\n",
      "Mean Test Score: 0.5682866184448463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbaldonado/miniforge3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/gbaldonado/miniforge3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/gbaldonado/miniforge3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'HNSC': {'model': RandomForestClassifier(max_depth=21, max_features=61, min_samples_split=42,\n",
       "                         n_estimators=51, random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'gini',\n",
       "   'max_depth': 21,\n",
       "   'max_features': 61,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 42,\n",
       "   'n_estimators': 51},\n",
       "  'test_score': 0.8140096618357487,\n",
       "  'mean_train_score': 0.9432654973230541,\n",
       "  'mean_validation_score': 0.817882630423614,\n",
       "  'confusion_matrix': array([[48,  6],\n",
       "         [ 6, 17]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.89      0.89      0.89        54\\n           1       0.74      0.74      0.74        23\\n\\n    accuracy                           0.84        77\\n   macro avg       0.81      0.81      0.81        77\\nweighted avg       0.84      0.84      0.84        77\\n'},\n",
       " 'STAD': {'model': RandomForestClassifier(max_depth=11, max_features=101, n_estimators=101,\n",
       "                         random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 101,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  'test_score': 0.7372958257713249,\n",
       "  'mean_train_score': 0.9780807270783214,\n",
       "  'mean_validation_score': 0.8246120546120548,\n",
       "  'confusion_matrix': array([[55,  3],\n",
       "         [ 9, 10]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.86      0.95      0.90        58\\n           1       0.77      0.53      0.62        19\\n\\n    accuracy                           0.84        77\\n   macro avg       0.81      0.74      0.76        77\\nweighted avg       0.84      0.84      0.83        77\\n'},\n",
       " 'COAD': {'model': RandomForestClassifier(max_depth=11, max_features=61, min_samples_split=42,\n",
       "                         n_estimators=101, random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 61,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 42,\n",
       "   'n_estimators': 101},\n",
       "  'test_score': 0.8956442831215972,\n",
       "  'mean_train_score': 0.953363617482942,\n",
       "  'mean_validation_score': 0.9133266733266734,\n",
       "  'confusion_matrix': array([[52,  6],\n",
       "         [ 2, 17]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.96      0.90      0.93        58\\n           1       0.74      0.89      0.81        19\\n\\n    accuracy                           0.90        77\\n   macro avg       0.85      0.90      0.87        77\\nweighted avg       0.91      0.90      0.90        77\\n'},\n",
       " 'ESCA': {'model': RandomForestClassifier(criterion='entropy', max_depth=11, max_features=81,\n",
       "                         min_samples_split=22, n_estimators=1, random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'entropy',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 81,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 22,\n",
       "   'n_estimators': 1},\n",
       "  'test_score': 0.6446078431372549,\n",
       "  'mean_train_score': 0.8013936095683135,\n",
       "  'mean_validation_score': 0.6898974709501025,\n",
       "  'confusion_matrix': array([[65,  3],\n",
       "         [ 6,  3]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.92      0.96      0.94        68\\n           1       0.50      0.33      0.40         9\\n\\n    accuracy                           0.88        77\\n   macro avg       0.71      0.64      0.67        77\\nweighted avg       0.87      0.88      0.87        77\\n'},\n",
       " 'READ': {'model': RandomForestClassifier(max_depth=11, max_features=61, n_estimators=1,\n",
       "                         random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 61,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 1},\n",
       "  'test_score': 0.5,\n",
       "  'mean_train_score': 0.8270556092091293,\n",
       "  'mean_validation_score': 0.5682866184448463,\n",
       "  'confusion_matrix': array([[70,  0],\n",
       "         [ 7,  0]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.91      1.00      0.95        70\\n           1       0.00      0.00      0.00         7\\n\\n    accuracy                           0.91        77\\n   macro avg       0.45      0.50      0.48        77\\nweighted avg       0.83      0.91      0.87        77\\n'}}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2_nmf_report = perform_gridsearchcv(exp2_datasets_nmf, classes)\n",
    "exp2_nmf_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the classification reports for all the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HNSC vs All\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        54\n",
      "           1       0.74      0.74      0.74        23\n",
      "\n",
      "    accuracy                           0.84        77\n",
      "   macro avg       0.81      0.81      0.81        77\n",
      "weighted avg       0.84      0.84      0.84        77\n",
      "\n",
      "STAD vs All\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90        58\n",
      "           1       0.77      0.53      0.62        19\n",
      "\n",
      "    accuracy                           0.84        77\n",
      "   macro avg       0.81      0.74      0.76        77\n",
      "weighted avg       0.84      0.84      0.83        77\n",
      "\n",
      "COAD vs All\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93        58\n",
      "           1       0.74      0.89      0.81        19\n",
      "\n",
      "    accuracy                           0.90        77\n",
      "   macro avg       0.85      0.90      0.87        77\n",
      "weighted avg       0.91      0.90      0.90        77\n",
      "\n",
      "ESCA vs All\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        68\n",
      "           1       0.50      0.33      0.40         9\n",
      "\n",
      "    accuracy                           0.88        77\n",
      "   macro avg       0.71      0.64      0.67        77\n",
      "weighted avg       0.87      0.88      0.87        77\n",
      "\n",
      "READ vs All\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        70\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.91        77\n",
      "   macro avg       0.45      0.50      0.48        77\n",
      "weighted avg       0.83      0.91      0.87        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in classes:\n",
    "    print(f\"{c} vs All\")\n",
    "    print(exp2_nmf_report[c][\"classification_report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can assess how the models are doing. It gives us a full report of the f1-score, recall, and preicions for all of our classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_hyperparameter_to_df(nested_dict, exp_name):\n",
    "    \"Save the scores\"\n",
    "    path = \"./dataset/microbiome_preprocessed_files/\"\n",
    "    data = []\n",
    "\n",
    "    for key, value in nested_dict.items():\n",
    "        entry = {'label': key}\n",
    "        entry.update(value['best_hyperparameters'])\n",
    "        entry['test_score'] = value['test_score']\n",
    "        entry['mean_train_score'] = value['mean_train_score']\n",
    "        entry['mean_validation_score'] = value['mean_validation_score']\n",
    "        data.append(entry)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    df.to_csv(path+f\"{exp_name}_best_hyperparam.csv\", index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_nmf_best_hyperparam_df = best_hyperparameter_to_df(exp2_nmf_report, \"exp2_nmf_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  HNSC\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 21, 'max_features': 61, 'min_samples_leaf': 1, 'min_samples_split': 42, 'n_estimators': 51}\n",
      "Confusion matrix for HNSC\n",
      "Accuracy on Test Set: 0.8047504025764896\n",
      "Mean Train Score: 0.9348363099535199\n",
      "Mean Test Score: 0.83845593386577\n",
      "Class:  STAD\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 11, 'max_features': 101, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 101}\n",
      "Confusion matrix for STAD\n",
      "Accuracy on Test Set: 0.7459165154264973\n",
      "Mean Train Score: 0.980379577653034\n",
      "Mean Test Score: 0.8293972693972694\n",
      "Class:  COAD\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 11, 'max_features': 61, 'min_samples_leaf': 1, 'min_samples_split': 42, 'n_estimators': 101}\n",
      "Confusion matrix for COAD\n",
      "Accuracy on Test Set: 0.8956442831215972\n",
      "Mean Train Score: 0.9532422533479344\n",
      "Mean Test Score: 0.9146253746253746\n",
      "Class:  ESCA\n",
      "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 11, 'max_features': 81, 'min_samples_leaf': 1, 'min_samples_split': 22, 'n_estimators': 1}\n",
      "Confusion matrix for ESCA\n",
      "Accuracy on Test Set: 0.6854575163398693\n",
      "Mean Train Score: 0.8032271133172857\n",
      "Mean Test Score: 0.6687457279562542\n",
      "Class:  READ\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 11, 'max_features': 61, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1}\n",
      "Confusion matrix for READ\n",
      "Accuracy on Test Set: 0.5\n",
      "Mean Train Score: 0.8357957635650208\n",
      "Mean Test Score: 0.6456080470162748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbaldonado/miniforge3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/gbaldonado/miniforge3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/gbaldonado/miniforge3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'HNSC': {'model': RandomForestClassifier(max_depth=21, max_features=61, min_samples_split=42,\n",
       "                         n_estimators=51, random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'gini',\n",
       "   'max_depth': 21,\n",
       "   'max_features': 61,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 42,\n",
       "   'n_estimators': 51},\n",
       "  'test_score': 0.8047504025764896,\n",
       "  'mean_train_score': 0.9348363099535199,\n",
       "  'mean_validation_score': 0.83845593386577,\n",
       "  'confusion_matrix': array([[47,  7],\n",
       "         [ 6, 17]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.89      0.87      0.88        54\\n           1       0.71      0.74      0.72        23\\n\\n    accuracy                           0.83        77\\n   macro avg       0.80      0.80      0.80        77\\nweighted avg       0.83      0.83      0.83        77\\n'},\n",
       " 'STAD': {'model': RandomForestClassifier(max_depth=11, max_features=101, n_estimators=101,\n",
       "                         random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 101,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  'test_score': 0.7459165154264973,\n",
       "  'mean_train_score': 0.980379577653034,\n",
       "  'mean_validation_score': 0.8293972693972694,\n",
       "  'confusion_matrix': array([[56,  2],\n",
       "         [ 9, 10]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.86      0.97      0.91        58\\n           1       0.83      0.53      0.65        19\\n\\n    accuracy                           0.86        77\\n   macro avg       0.85      0.75      0.78        77\\nweighted avg       0.85      0.86      0.85        77\\n'},\n",
       " 'COAD': {'model': RandomForestClassifier(max_depth=11, max_features=61, min_samples_split=42,\n",
       "                         n_estimators=101, random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 61,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 42,\n",
       "   'n_estimators': 101},\n",
       "  'test_score': 0.8956442831215972,\n",
       "  'mean_train_score': 0.9532422533479344,\n",
       "  'mean_validation_score': 0.9146253746253746,\n",
       "  'confusion_matrix': array([[52,  6],\n",
       "         [ 2, 17]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.96      0.90      0.93        58\\n           1       0.74      0.89      0.81        19\\n\\n    accuracy                           0.90        77\\n   macro avg       0.85      0.90      0.87        77\\nweighted avg       0.91      0.90      0.90        77\\n'},\n",
       " 'ESCA': {'model': RandomForestClassifier(criterion='entropy', max_depth=11, max_features=81,\n",
       "                         min_samples_split=22, n_estimators=1, random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'entropy',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 81,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 22,\n",
       "   'n_estimators': 1},\n",
       "  'test_score': 0.6854575163398693,\n",
       "  'mean_train_score': 0.8032271133172857,\n",
       "  'mean_validation_score': 0.6687457279562542,\n",
       "  'confusion_matrix': array([[63,  5],\n",
       "         [ 5,  4]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.93      0.93      0.93        68\\n           1       0.44      0.44      0.44         9\\n\\n    accuracy                           0.87        77\\n   macro avg       0.69      0.69      0.69        77\\nweighted avg       0.87      0.87      0.87        77\\n'},\n",
       " 'READ': {'model': RandomForestClassifier(max_depth=11, max_features=61, n_estimators=1,\n",
       "                         random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 61,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 1},\n",
       "  'test_score': 0.5,\n",
       "  'mean_train_score': 0.8357957635650208,\n",
       "  'mean_validation_score': 0.6456080470162748,\n",
       "  'confusion_matrix': array([[70,  0],\n",
       "         [ 7,  0]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.91      1.00      0.95        70\\n           1       0.00      0.00      0.00         7\\n\\n    accuracy                           0.91        77\\n   macro avg       0.45      0.50      0.48        77\\nweighted avg       0.83      0.91      0.87        77\\n'}}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2_lda_report = perform_gridsearchcv(exp2_datasets_lda, classes)\n",
    "exp2_lda_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_lda_best_hyperparam_df = best_hyperparameter_to_df(exp2_lda_report, \"exp2_lda_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  HNSC\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 21, 'max_features': 61, 'min_samples_leaf': 1, 'min_samples_split': 42, 'n_estimators': 51}\n",
      "Confusion matrix for HNSC\n",
      "Accuracy on Test Set: 0.823268921095008\n",
      "Mean Train Score: 0.9458994255220672\n",
      "Mean Test Score: 0.811541263836346\n",
      "Class:  STAD\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 11, 'max_features': 101, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 101}\n",
      "Confusion matrix for STAD\n",
      "Accuracy on Test Set: 0.7459165154264973\n",
      "Mean Train Score: 0.9942261427425823\n",
      "Mean Test Score: 0.8124442224442225\n",
      "Class:  COAD\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 11, 'max_features': 61, 'min_samples_leaf': 1, 'min_samples_split': 42, 'n_estimators': 101}\n",
      "Confusion matrix for COAD\n",
      "Accuracy on Test Set: 0.9219600725952812\n",
      "Mean Train Score: 0.9522587192498845\n",
      "Mean Test Score: 0.9100799200799201\n",
      "Class:  ESCA\n",
      "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 11, 'max_features': 81, 'min_samples_leaf': 1, 'min_samples_split': 22, 'n_estimators': 1}\n",
      "Confusion matrix for ESCA\n",
      "Accuracy on Test Set: 0.6004901960784313\n",
      "Mean Train Score: 0.7597366872025251\n",
      "Mean Test Score: 0.5700786056049214\n",
      "Class:  READ\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 11, 'max_features': 61, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1}\n",
      "Confusion matrix for READ\n",
      "Accuracy on Test Set: 0.4928571428571429\n",
      "Mean Train Score: 0.8458981512237175\n",
      "Mean Test Score: 0.6026198010849908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'HNSC': {'model': RandomForestClassifier(max_depth=21, max_features=61, min_samples_split=42,\n",
       "                         n_estimators=51, random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'gini',\n",
       "   'max_depth': 21,\n",
       "   'max_features': 61,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 42,\n",
       "   'n_estimators': 51},\n",
       "  'test_score': 0.823268921095008,\n",
       "  'mean_train_score': 0.9458994255220672,\n",
       "  'mean_validation_score': 0.811541263836346,\n",
       "  'confusion_matrix': array([[49,  5],\n",
       "         [ 6, 17]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.89      0.91      0.90        54\\n           1       0.77      0.74      0.76        23\\n\\n    accuracy                           0.86        77\\n   macro avg       0.83      0.82      0.83        77\\nweighted avg       0.86      0.86      0.86        77\\n'},\n",
       " 'STAD': {'model': RandomForestClassifier(max_depth=11, max_features=101, n_estimators=101,\n",
       "                         random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 101,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 101},\n",
       "  'test_score': 0.7459165154264973,\n",
       "  'mean_train_score': 0.9942261427425823,\n",
       "  'mean_validation_score': 0.8124442224442225,\n",
       "  'confusion_matrix': array([[56,  2],\n",
       "         [ 9, 10]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.86      0.97      0.91        58\\n           1       0.83      0.53      0.65        19\\n\\n    accuracy                           0.86        77\\n   macro avg       0.85      0.75      0.78        77\\nweighted avg       0.85      0.86      0.85        77\\n'},\n",
       " 'COAD': {'model': RandomForestClassifier(max_depth=11, max_features=61, min_samples_split=42,\n",
       "                         n_estimators=101, random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 61,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 42,\n",
       "   'n_estimators': 101},\n",
       "  'test_score': 0.9219600725952812,\n",
       "  'mean_train_score': 0.9522587192498845,\n",
       "  'mean_validation_score': 0.9100799200799201,\n",
       "  'confusion_matrix': array([[52,  6],\n",
       "         [ 1, 18]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.98      0.90      0.94        58\\n           1       0.75      0.95      0.84        19\\n\\n    accuracy                           0.91        77\\n   macro avg       0.87      0.92      0.89        77\\nweighted avg       0.92      0.91      0.91        77\\n'},\n",
       " 'ESCA': {'model': RandomForestClassifier(criterion='entropy', max_depth=11, max_features=81,\n",
       "                         min_samples_split=22, n_estimators=1, random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'entropy',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 81,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 22,\n",
       "   'n_estimators': 1},\n",
       "  'test_score': 0.6004901960784313,\n",
       "  'mean_train_score': 0.7597366872025251,\n",
       "  'mean_validation_score': 0.5700786056049214,\n",
       "  'confusion_matrix': array([[59,  9],\n",
       "         [ 6,  3]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.91      0.87      0.89        68\\n           1       0.25      0.33      0.29         9\\n\\n    accuracy                           0.81        77\\n   macro avg       0.58      0.60      0.59        77\\nweighted avg       0.83      0.81      0.82        77\\n'},\n",
       " 'READ': {'model': RandomForestClassifier(max_depth=11, max_features=61, n_estimators=1,\n",
       "                         random_state=42),\n",
       "  'best_hyperparameters': {'criterion': 'gini',\n",
       "   'max_depth': 11,\n",
       "   'max_features': 61,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 1},\n",
       "  'test_score': 0.4928571428571429,\n",
       "  'mean_train_score': 0.8458981512237175,\n",
       "  'mean_validation_score': 0.6026198010849908,\n",
       "  'confusion_matrix': array([[69,  1],\n",
       "         [ 7,  0]]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.91      0.99      0.95        70\\n           1       0.00      0.00      0.00         7\\n\\n    accuracy                           0.90        77\\n   macro avg       0.45      0.49      0.47        77\\nweighted avg       0.83      0.90      0.86        77\\n'}}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2_pca_report = perform_gridsearchcv(exp2_datasets_pca, classes)\n",
    "exp2_pca_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_pca_best_hyperparam_df = best_hyperparameter_to_df(exp2_pca_report, \"exp2_pca_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the test scores**\n",
    "\n",
    "For data visualization we can use matplotlib. Here's how you can graph the test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_test_scores(data):\n",
    "    # Create a DataFrame from the input data\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Plot 'test_score' for all labels in the same graph\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(df['label'], df['test_score'], color='skyblue')\n",
    "\n",
    "    # Display labels on each bar\n",
    "    for i, value in enumerate(df['test_score']):\n",
    "        plt.text(i, value, round(value, 3), ha='center', va='bottom')\n",
    "\n",
    "    plt.title('Test Scores by Label')\n",
    "    plt.xlabel('Label')\n",
    "    plt.ylabel('Test Score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_test_scores(exp2_pca_best_hyperparam_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We have accomplished experiment 2. This is the end of the 3-part series that demonstrated the learning outcomes for this class. CONGRATS!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
