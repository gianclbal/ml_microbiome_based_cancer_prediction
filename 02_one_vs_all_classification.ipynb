{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gianclbal/ml_microbiome_based_cancer_prediction/blob/master/02_one_vs_all_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n63xFPlJYiCL"
      },
      "source": [
        "# **Experiment 1: One vs All Classification**\n",
        "\n",
        "## ***Objectives for this Notebook***\n",
        "* Showcase One vs All classification, train/test/validation split, cross validation, and GridSearchCV\n",
        "\n",
        "**One vs All Classification (OvA)**, also known as One-vs-Rest (OvR), is a strategy used in machine learning for multi-class classification problems. In a multi-class classification task, there are more than two possible classes or categories that a given input can belong to. The goal of OvA is to extend binary classification algorithms to handle multi-class scenarios.\n",
        "\n",
        "Here's a brief explanation of the One-vs-All strategy:\n",
        "\n",
        "1. **Binary Classification for Each Class**: For each unique class in the multi-class problem, a binary classifier is trained. This means that if there are k classes, you will train k binary classifiers.\n",
        "\n",
        "2. **Training Process**: For a specific class, the samples belonging to that class are considered as the positive class, and all other samples from other classes are considered as the negative class.\n",
        "The binary classifier is trained to distinguish between the samples of the current class and the samples from all other classes.\n",
        "\n",
        "3. **Decision Making**: During the prediction phase, each binary classifier makes a prediction, and the class associated with the classifier that outputs the highest confidence is chosen as the final prediction.\n",
        "\n",
        "This way, the problem of multi-class classification is transformed into multiple independent binary classification sub-problems. The following is our setup for this experiment:\n",
        "* **Head and neck cancer (HNSC) vs All**\n",
        "* **Stomach cancer (STAD) vs All**\n",
        "* **Colon cancer (COAD) vs All**\n",
        "* **Esophageal cancer (ESCA) vs All**\n",
        "* **Rectal cancer (READ) vs All**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cbM_tPFYiCM"
      },
      "source": [
        "## **1.) Loading the dataset and setting parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2gO94rKCYiCM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Training\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Evaluation\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import make_scorer, balanced_accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import random\n",
        "from sklearn.utils import check_random_state\n",
        "\n",
        "seed_value = 42\n",
        "\n",
        "# Set Python seed\n",
        "random.seed(seed_value)\n",
        "\n",
        "# Set NumPy seed\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# Set scikit-learn seed\n",
        "sklearn_random_state = check_random_state(seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If running colab:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hxSrldruaWzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigate to where you saved the file from notebook 1, this is where I saved mine\n",
        "microbiome_df = pd.read_csv(\"/content/drive/MyDrive/microbiome_dataset/microbiome_preprocessed_files/microbiome_merged_dfs.csv\")"
      ],
      "metadata": {
        "id": "hFg_4VdWYjmN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mkd0utMKYiCN"
      },
      "outputs": [],
      "source": [
        "# Locally\n",
        "microbiome_df = pd.read_csv(\"./dataset/microbiome_preprocessed_files/microbiome_merged_dfs.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "tYuwlhKtYiCN",
        "outputId": "c387b40d-2aff-4c83-aa1f-074a9729aeb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 133)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           SampleID  Simonsiella  Treponema  Campylobacter  Helicobacter  \\\n",
              "0  TCGA-CG-5720-01A          0.0        0.0       0.000000      0.895050   \n",
              "1  TCGA-CN-4741-01A          0.0        0.0       0.010470      0.000000   \n",
              "2  TCGA-BR-6801-01A          0.0        0.0       0.000000      0.000000   \n",
              "3  TCGA-IG-A3I8-01A          0.0        0.0       0.000000      0.067717   \n",
              "4  TCGA-L5-A4OT-01A          0.0        0.0       0.012202      0.000000   \n",
              "\n",
              "   Paracoccus  Comamonas  Pseudomonas  Xanthomonas  Agrobacterium  ...  \\\n",
              "0         0.0        0.0          0.0          0.0            0.0  ...   \n",
              "1         0.0        0.0          0.0          0.0            0.0  ...   \n",
              "2         0.0        0.0          0.0          0.0            0.0  ...   \n",
              "3         0.0        0.0          0.0          0.0            0.0  ...   \n",
              "4         0.0        0.0          0.0          0.0            0.0  ...   \n",
              "\n",
              "   Hungatella  Pseudopropionibacterium  Peptoanaerobacter  Emergencia  \\\n",
              "0         0.0                      0.0                0.0         0.0   \n",
              "1         0.0                      0.0                0.0         0.0   \n",
              "2         0.0                      0.0                0.0         0.0   \n",
              "3         0.0                      0.0                0.0         0.0   \n",
              "4         0.0                      0.0                0.0         0.0   \n",
              "\n",
              "   Prevotellamassilia  Criibacterium  Fournierella  Negativibacillus  \\\n",
              "0                 0.0            0.0           0.0               0.0   \n",
              "1                 0.0            0.0           0.0               0.0   \n",
              "2                 0.0            0.0           0.0               0.0   \n",
              "3                 0.0            0.0           0.0               0.0   \n",
              "4                 0.0            0.0           0.0               0.0   \n",
              "\n",
              "   Duodenibacillus  label  \n",
              "0              0.0   STAD  \n",
              "1              0.0   HNSC  \n",
              "2              0.0   STAD  \n",
              "3              0.0   ESCA  \n",
              "4              0.0   ESCA  \n",
              "\n",
              "[5 rows x 133 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3896738a-6954-46f4-b100-eed159f1f582\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SampleID</th>\n",
              "      <th>Simonsiella</th>\n",
              "      <th>Treponema</th>\n",
              "      <th>Campylobacter</th>\n",
              "      <th>Helicobacter</th>\n",
              "      <th>Paracoccus</th>\n",
              "      <th>Comamonas</th>\n",
              "      <th>Pseudomonas</th>\n",
              "      <th>Xanthomonas</th>\n",
              "      <th>Agrobacterium</th>\n",
              "      <th>...</th>\n",
              "      <th>Hungatella</th>\n",
              "      <th>Pseudopropionibacterium</th>\n",
              "      <th>Peptoanaerobacter</th>\n",
              "      <th>Emergencia</th>\n",
              "      <th>Prevotellamassilia</th>\n",
              "      <th>Criibacterium</th>\n",
              "      <th>Fournierella</th>\n",
              "      <th>Negativibacillus</th>\n",
              "      <th>Duodenibacillus</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TCGA-CG-5720-01A</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.895050</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>STAD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TCGA-CN-4741-01A</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010470</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HNSC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TCGA-BR-6801-01A</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>STAD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TCGA-IG-A3I8-01A</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.067717</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ESCA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TCGA-L5-A4OT-01A</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.012202</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ESCA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 133 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3896738a-6954-46f4-b100-eed159f1f582')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3896738a-6954-46f4-b100-eed159f1f582 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3896738a-6954-46f4-b100-eed159f1f582');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-113bb3b0-5aa3-4eeb-8790-1fd181a435f2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-113bb3b0-5aa3-4eeb-8790-1fd181a435f2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-113bb3b0-5aa3-4eeb-8790-1fd181a435f2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "print(microbiome_df.shape)\n",
        "microbiome_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH9kHqlwYiCN"
      },
      "source": [
        "## **2.) Creating a data slicer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e938Ve-eYiCN"
      },
      "source": [
        "We will create our own data slicer that will fetch the relevant data from our dataframe.\n",
        "\n",
        "For experiment 1 using OvA, since we 5 classes, we will have 5 binary classifiers. Because we have 5 binary classifiers, we will need also need 5 datasets. For each dataset, we have a different cancer class that is targeted (positive class) and the samples from the remaining classes were grouped together into one major class (negative class), to make a binary classification problem.\n",
        "\n",
        "The data slicer takes in the data we processed from the first notebook, and outputs a dictionary of datasets for experiment 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiBpw06jYiCN"
      },
      "outputs": [],
      "source": [
        "classes = [\"HNSC\", \"STAD\", \"COAD\", \"ESCA\", \"READ\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lHBtSSBYiCN",
        "outputId": "ce09b05b-e3b1-491a-8e7b-b169ddd541b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "HNSC    155\n",
              "STAD    127\n",
              "COAD    125\n",
              "ESCA     60\n",
              "READ     45\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show the counts for each class in the df\n",
        "microbiome_df[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQSd1pY9YiCO"
      },
      "outputs": [],
      "source": [
        "def exp_1_data_slicer(dataframe, label_column, classes, train_test=True):\n",
        "    \"\"\"\n",
        "    Generate a one-vs-all dataset for a specific class for experiment 1\n",
        "\n",
        "    Parameters:\n",
        "    - dataframe: pd.DataFrame, the input DataFrame.\n",
        "    - label_column: str, the column name representing the labels.\n",
        "    - classes: list, the classes.\n",
        "\n",
        "    Returns:\n",
        "    - dataset_dict: a dictionary where the keys is the targeted class and the values are its corresponding features and labels\n",
        "    \"\"\"\n",
        "\n",
        "    dataset_dict = {}\n",
        "\n",
        "    for i in classes:\n",
        "        positive_class = i\n",
        "        dframe = dataframe.copy()\n",
        "        dframe['label'] = [1 if x == positive_class else 0 for x in dataframe[label_column]]\n",
        "        print(i)\n",
        "        print(dframe.label.value_counts())\n",
        "        X = dframe.drop([\"SampleID\", \"label\"], axis=1)\n",
        "        y = dframe[\"label\"]\n",
        "        if train_test:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=seed_value)\n",
        "            dataset_dict[positive_class] = {\"train\": (X_train, y_train),\n",
        "                                            \"test\": (X_test, y_test)}\n",
        "        else:\n",
        "            dataset_dict[positive_class] = {\"feature\": X,\n",
        "                                            \"label\": y}\n",
        "\n",
        "    return dataset_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV6nmbwPYiCO",
        "outputId": "809c25f2-32ae-491a-9629-426dc48d391d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HNSC\n",
            "label\n",
            "0    357\n",
            "1    155\n",
            "Name: count, dtype: int64\n",
            "STAD\n",
            "label\n",
            "0    385\n",
            "1    127\n",
            "Name: count, dtype: int64\n",
            "COAD\n",
            "label\n",
            "0    387\n",
            "1    125\n",
            "Name: count, dtype: int64\n",
            "ESCA\n",
            "label\n",
            "0    452\n",
            "1     60\n",
            "Name: count, dtype: int64\n",
            "READ\n",
            "label\n",
            "0    467\n",
            "1     45\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Show the distribution per each class\n",
        "exp1_datasets = exp_1_data_slicer(microbiome_df, \"label\", classes, train_test=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgiInXLdYiCO"
      },
      "source": [
        "Let's go over how the data is structured in our dictionary.\n",
        "```\n",
        "exp_1_dataset: {\n",
        "    targeted_class_1: {\n",
        "        train_1: [features_1, target_1],\n",
        "        test_1: [features_1, target_1]\n",
        "    },\n",
        "    targeted_class_2: {\n",
        "        train_2: [features_2, target_2],\n",
        "        test_2: [features_2, target_2]\n",
        "    },...,\n",
        "    targeted_class_n: {\n",
        "        train_n: [features_n, target_n],\n",
        "        test_n: [features_n, target_n]\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "So, for example to access the class \"HNSC\" train features and targets, we can run:\n",
        "```\n",
        "features = exp1_datasets[\"HNSC\"][\"train\"][0]\n",
        "target = exp1_datasets[\"HNSC\"][\"train\"][1]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C_494VVYiCO"
      },
      "source": [
        "**Train, validation, and test splits. What is the validation set?**\n",
        "In your introduction to machine learning class, you may remember that you split your dataset into a training and test set. The training set is the dataset reserved for the learning or training of the model, and the test set was reserved for the evaluation of the model (how good the model is performing). If you're working with only one model, maybe this setup is sufficient. But in reality, you will be working with multiple models, and in order to pick the best model, you will need another dataset reserved for this. This dataset is called the `validation set`.\n",
        "\n",
        "Definitions of the types of dataset:\n",
        "* **Training set**: A subset of the data used to \"teach\" the machine learning model.\n",
        "* **Test set**: A subset of the data kept completely unseen by the model during training. It provides an unbiased, real-world assessment of the model's performance.\n",
        "* **Validation set**: A smaller subset of data extracted from the training set, used to optimize and select the best model before final testing.\n",
        "\n",
        "**Train, validation, and test splits. What is the validation set?**\n",
        "In your introduction to machine learning class, you may remember that you split your dataset into a training and test set. The training set is the dataset reserved for the learning or training of the model (in order words, setting model parameters), and the test set was reserved for the evaluation of the model (how good the model is performing). For simpler ML algorithms this is sufficient, but many ML algorithms also use hyperparameters (in addition to model parameters). To find the right setting for these hyperparameters we use the validation split or set.  \n",
        "\n",
        "Definitions of the types of dataset:\n",
        "* **Training set**: A subset of the labeled data used to \"teach\" the machine learning model. What this implies internally is that this labeled data is used to find the right settings for the model’s parameters.  \n",
        "* **Validation set**: Typically a smaller subset of labeled data that is used to find the right settings for the hyperparameters of the trained model. This step is also referred to as tuning the model.\n",
        "* **Test set**: A subset of the labeled data kept completely unseen by the model during training and validation. The final model (after training and tuning has been done) is tested on this subset of data, and model performance assessment is made by comparing the predicted labels with the ground truth labels.\n",
        "![Screenshot 2024-01-14 at 5.18.16 PM.png](<attachment:Screenshot 2024-01-14 at 5.18.16 PM.png>) Screenshot taken from https://youtu.be/NPWlj9G1Si8. Learn more about train-validation-test split here: https://youtu.be/NPWlj9G1Si8\n",
        "\n",
        "The rough standard for train-validation-test split is 60-80% goes to training, 10-20% goes to validation, and 10-20% goes to test.\n",
        "\n",
        "In this notebook, you'll notice that for the data slicer, we've only split the dataset into `train` and `test`. Later in the next section, you'll split the training set into `train` and `validation`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_3-Dc2PYiCO"
      },
      "source": [
        "Finally, we are done working with the data. The next section will go over model creation for the HSNC class using cross-validation and hyperparameter grid search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SK-uTMdYiCO"
      },
      "source": [
        "## **3.) Cross Validation and Hyperparameter Grid Search**\n",
        "\n",
        "When performing the usual train/validation/test split for model training and testing, the model undergoes training on a specific randomly selected subset of the data, validation on another distinct set of data, and finally is tested on a separate holdout dataset. However, this approach can pose challenges, particularly with relatively small datasets, as it may exclude crucial observations essential for training an optimal model. Reserving a percentage of data outside the training phase, even if it's in the range of 15–25%, retains valuable information that can significantly enhance the effectiveness of our model training.\n",
        "\n",
        "The solution is cross validation.\n",
        "\n",
        "**Cross validation**: Entails dividing the dataset into random groups, reserving one group as the test set, and training the model on the remaining groups. This process is iterated for each group designated as the test set, and the resulting models are averaged to create the final model.\n",
        "\n",
        "Here's a simple diagram of how it works:\n",
        "![image.png](attachment:image.png)\n",
        "Image from scikit-learn website: https://scikit-learn.org/stable/modules/cross_validation.html\n",
        "\n",
        "Read more how it works here: https://www.geeksforgeeks.org/cross-validation-machine-learning/\n",
        "\n",
        "While cross validation can definitely benefit model development, one important drawback is that it is computationally expensive as the dataset gets larget and as the value of k increases. For the remainder of this section, we will look on how to implement cross validation on random forest. Additionally, we will run the model over a grid of hyperparmeters in order to identify optimal result.\n",
        "\n",
        "**Hyperparameter Grid Search**: Systematically explores different hyperparameter combinations to find the best configuration for a model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwdQTmlbYiCO"
      },
      "source": [
        "### **a) Training**\n",
        "\n",
        "We will use HNSC vs All as an example first. For our classifier we will use Random Forest. For our cross validation object, we will use the library `StratifiedKFold` and set split to 5, shuffle to True, and declare the random state equal to our seed value.\n",
        "\n",
        "**Validation set with StratifiedKFold**: In scikit-learn's StratifiedKFold, the dataset is divided into k folds, while ensuring each fold maintains the same class distribution as the original dataset. It takes care of creating the validation set and the truthful training sets using the training set we defined from the data slicer. The ratio of the validation set from the training set is `1/n_splits`.\n",
        "\n",
        "Read more about `StratifiedKFold` here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kiop2Q7DYiCO"
      },
      "outputs": [],
      "source": [
        "features = exp1_datasets[\"HNSC\"][\"train\"][0]\n",
        "target = exp1_datasets[\"HNSC\"][\"train\"][1]\n",
        "\n",
        "rf = RandomForestClassifier(random_state=seed_value)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU-yE7PjYiCO"
      },
      "source": [
        "Now let's create a grid of parameters values for our random forest classification model. The first parameter is n_estimators, which is the number of trees used in our random forest model. Read the rest of the definitions of the hyperparameters in sklearn's website: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFm5uB0kYiCO"
      },
      "source": [
        "The next two cells are hyperparameter grids. The first `param_grid_orig` is the parameter grid that the paper used for hyperparameter fine-tuning.  Using this grid will take some time because of the many possible combinations. I recommend you use the second `param_grid`, a distilled version of the first one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MbEMoaoYiCO"
      },
      "outputs": [],
      "source": [
        "# This grid is used in the paper (will run slower)\n",
        "param_grid_orig = {\n",
        "    'n_estimators': list(range(1, 401)),\n",
        "    'criterion': ['gini', 'entropy'],  # Gini impurity or Shannon information gain\n",
        "    'min_samples_split': list(range(2, 101)),\n",
        "    'min_samples_leaf': list(range(1, 21)),\n",
        "    'max_depth': list(range(1, 51)),  # Specify the range when max_depth is used\n",
        "    'max_features': list(range(1, features.shape[1] + 1))  # 1 to maximum number of features\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GotYBq6YiCO"
      },
      "outputs": [],
      "source": [
        "# This grid is a distilled version of what's used in the paper (will run faster)\n",
        "param_grid = {\n",
        "    'n_estimators': list(range(1, 401, 50)), #skips every 50\n",
        "    'criterion': ['gini', 'entropy'],  # Gini impurity or Shannon information gain\n",
        "    'min_samples_split': list(range(2, 101,20)),\n",
        "    'min_samples_leaf': list(range(1, 21,10)),\n",
        "    'max_depth': list(range(1, 51,10)),  # Specify the range when max_depth is used\n",
        "    'max_features': list(range(1, features.shape[1] + 1, 20))  # 1 to maximum number of features\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqb16ml9YiCO"
      },
      "source": [
        "**GridSearchCV:**\n",
        "The module we will be utilizing is sklearn’s GridSearchCV, which will allow us to pass our specific estimator, our grid of parameters, our preferred scoring metric, and our cross validation object. The documentation for this method can be found here. The main parameters are highlighted below:\n",
        "\n",
        "* **estimator**: this parameter allows you to select the specific model you’re choosing to run, in our case Random Forest Classification.\n",
        "* **param_grid**: this parameter allows you to pass the grid of parameters you are searching. This grid must be formatted as a dictionary with the key corresponding to the specific estimator’s parameter names, and the values corresponding to a list of values to pass for the specific parameters.\n",
        "* **scoring**: Strategy to evaluate the performance of the cross-validated model on the test set. For scoring, we will use `balanced_accuracy` as it is used in the paper. You can use other metrics as you wish.\n",
        "* **n_jobs**: Number of jobs to run in parallel. `None` means 1 and `-1` means use all processors.\n",
        "* **cv**: this parameter allows you to change the number of folds for the cross validation or a cross validation object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORy49dkbYiCO"
      },
      "outputs": [],
      "source": [
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    scoring=make_scorer(balanced_accuracy_score),  # Choose an appropriate metric for your problem\n",
        "    cv=cv,\n",
        "    n_jobs=6,  # Use all available processors,\n",
        "    return_train_score=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iGk981EYiCP",
        "outputId": "dadb4af7-0579-4b31-a7c7-d71085c2dc4c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
              "             estimator=RandomForestClassifier(random_state=42), n_jobs=6,\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [1, 11, 21, 31, 41],\n",
              "                         &#x27;max_features&#x27;: [1, 21, 41, 61, 81, 101, 121],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 11],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 22, 42, 62, 82],\n",
              "                         &#x27;n_estimators&#x27;: [1, 51, 101, 151, 201, 251, 301, 351]},\n",
              "             return_train_score=True,\n",
              "             scoring=make_scorer(balanced_accuracy_score))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
              "             estimator=RandomForestClassifier(random_state=42), n_jobs=6,\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [1, 11, 21, 31, 41],\n",
              "                         &#x27;max_features&#x27;: [1, 21, 41, 61, 81, 101, 121],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 11],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 22, 42, 62, 82],\n",
              "                         &#x27;n_estimators&#x27;: [1, 51, 101, 151, 201, 251, 301, 351]},\n",
              "             return_train_score=True,\n",
              "             scoring=make_scorer(balanced_accuracy_score))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
              "             estimator=RandomForestClassifier(random_state=42), n_jobs=6,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [1, 11, 21, 31, 41],\n",
              "                         'max_features': [1, 21, 41, 61, 81, 101, 121],\n",
              "                         'min_samples_leaf': [1, 11],\n",
              "                         'min_samples_split': [2, 22, 42, 62, 82],\n",
              "                         'n_estimators': [1, 51, 101, 151, 201, 251, 301, 351]},\n",
              "             return_train_score=True,\n",
              "             scoring=make_scorer(balanced_accuracy_score))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform the grid search\n",
        "## Note: This code will run a while depending on big your parameter grid search is.\n",
        "grid_search.fit(features, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccVYIye8YiCP",
        "outputId": "dbea3f40-5d35-4594-87db-fbca1c12794d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 21, 'max_features': 61, 'min_samples_leaf': 1, 'min_samples_split': 42, 'n_estimators': 51}\n"
          ]
        }
      ],
      "source": [
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXKoR7D6YiCP"
      },
      "outputs": [],
      "source": [
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ-PfndtYiCP"
      },
      "source": [
        "### **b.) Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5X7ZvJy-YiCP"
      },
      "outputs": [],
      "source": [
        "# Access cv_results_ attribute to get detailed results\n",
        "cv_results = grid_search.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEStWDwUYiCP",
        "outputId": "649fb674-1501-400c-f1ad-7577185cae7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "0    54\n",
            "1    23\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Get the test features and targets\n",
        "test_features = exp1_datasets[\"HNSC\"][\"test\"][0]\n",
        "test_target = exp1_datasets[\"HNSC\"][\"test\"][1]\n",
        "\n",
        "# Check class distribution of the test set\n",
        "print(test_target.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRLtawZZYiCP"
      },
      "source": [
        "**Balanced accuracy**: Balanced accuracy takes into account both sensitivity (true positive rate) and specificity (true negative rate) and provides a balanced view of the classifier's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evw3W6dzYiCP",
        "outputId": "d7941951-d360-4ee8-9b47-97cf7bd818ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.89      0.88        54\n",
            "           1       0.73      0.70      0.71        23\n",
            "\n",
            "    accuracy                           0.83        77\n",
            "   macro avg       0.80      0.79      0.80        77\n",
            "weighted avg       0.83      0.83      0.83        77\n",
            "\n",
            "Balanced Accuracy on Test Set: 0.7922705314009661\n",
            "\n",
            "Confusion matrix for HNSC \n",
            " [[48  6]\n",
            " [ 7 16]]\n",
            "\n",
            "True Positives: 16, True Negatives: 48, False Positives: 6, False Negatives: 7\n"
          ]
        }
      ],
      "source": [
        "# Get predictions\n",
        "predictions = best_model.predict(test_features)\n",
        "\n",
        "# Get classification report\n",
        "class_report = classification_report(test_target, predictions)\n",
        "print(class_report)\n",
        "\n",
        "# Get the balanced accuracy\n",
        "balanced_accuracy = balanced_accuracy_score(test_target, predictions)\n",
        "print(\"Balanced Accuracy on Test Set:\", balanced_accuracy)\n",
        "\n",
        "# Create a confusion matrix\n",
        "cm = confusion_matrix(test_target, predictions)\n",
        "print(f\"\\nConfusion matrix for HNSC \\n {c}\")\n",
        "print(f\"\\nTrue Positives: {cm[1, 1]}, True Negatives: {cm[0, 0]}, False Positives: {cm[0, 1]}, False Negatives: {cm[1, 0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky65N-cyYiCP",
        "outputId": "e4df9a70-f2b5-4045-c02a-7bc9fbcf4e4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Train Score: 0.9402205662678312\n",
            "Mean Validation Score: 0.8451345102984448\n"
          ]
        }
      ],
      "source": [
        "# Calculate mean train score and mean validation score\n",
        "# We have a mean train score and mean test score because our grid search did 5 splits, and the training and test scores of those splits need to be averaged.\n",
        "mean_train_score = cv_results['mean_train_score'][grid_search.best_index_]\n",
        "mean_validation_score = cv_results['mean_test_score'][grid_search.best_index_]\n",
        "\n",
        "print(\"Mean Train Score:\", mean_train_score)\n",
        "print(\"Mean Validation Score:\", mean_validation_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhCn9EshYiCP"
      },
      "outputs": [],
      "source": [
        "# Put everything in a report dictionary\n",
        "report = {}\n",
        "report[\"HNSC\"] = {\n",
        "    \"model\": best_model,\n",
        "    \"best_hyperparameters\": grid_search.best_params_,\n",
        "    \"accuracy_on_test\": balanced_accuracy,\n",
        "    \"mean_train_score\": mean_train_score,\n",
        "    \"mean_test_score\": mean_validation_score,\n",
        "    \"confusion_matrix\": cm,\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIMOnjtWYiCP"
      },
      "source": [
        "**Observations and Analysis**:\n",
        "\n",
        "This HNSC vs All model has a good balance between true positives and true negatives. A balanced accuracy on the test set of 0.79 is relatively high. The mean training score (0.94) is higher than the mean validation score (0.85), suggesting a possible overfitting, but the generalization to the test set is still reasonable. In summary, the model seems to perform well, but it's good to consider that this is only with one seed. In a professional research project, you would have to check for variance using different random seeds. I will provide the code below on how you can do this. For the sake of this project's simplicity, we would work with one seed value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLAOmQ8NYiCP"
      },
      "source": [
        "We have trained and evaluated a model for HNSC vs All using cross validation and grid search cross validation. Now, we need to perform the same steps for the rest of the classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M_jjxUoYiCP"
      },
      "source": [
        "## Task 1:\n",
        "\n",
        "We have trained and evaluated a model for HNSC vs All using cross validation and grid search cross validation. For this task, pick another Targeted Class vs All binary classification to train and evaluate.\n",
        "\n",
        "### a) Training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giMzLbpRYiCP"
      },
      "outputs": [],
      "source": [
        "# Write your code for training here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CAfbtYnYiCP"
      },
      "source": [
        "### b) Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDASEcx1YiCS"
      },
      "outputs": [],
      "source": [
        "# Write your code for evaluation here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqK33Q86YiCS"
      },
      "source": [
        "## **4.) Creating a Function to Go Over Each Class**\n",
        "\n",
        "Now we've gone over how grid search cross validation, let's create a function that will work on all of our 5 OvA classes at once.\n",
        "\n",
        "The input of this function are the following:\n",
        "* **dataset_dict**: The dictionary of our datasets\n",
        "* **classess**: A list of our classes\n",
        "* **cv_n_split**: An integer that determines how many splits to use in cross validation. Default `5`.\n",
        "* **n_jobs**: An integer that determines how many processes to use. Default `-1`, all processors.\n",
        "\n",
        "The output is the following:\n",
        "* **report**: A dictionary that includes the best model object, the best hyperparameters and evaluations, and the accuracy on the test set for each targeted label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vU0nASKYiCS"
      },
      "outputs": [],
      "source": [
        "def perform_gridsearchcv(dataset_dict, classes, seed=seed_value, cv_n_splits=5, n_jobs=-1):\n",
        "    \"\"\"\n",
        "    This function will perform GridSearchCV for each class.\n",
        "\n",
        "    inputs:\n",
        "    dataset_dict (dict): datasets from data_slicer()\n",
        "    classes (list): class names\n",
        "    seed (int): introduce randomness\n",
        "    cv_n_split (int): determines how many splits to use in cross validation. Default `5`.\n",
        "    n_jobs (int): determines how many processes to use. Default `-1`, all processors.\n",
        "\n",
        "    output:\n",
        "    report (dict): holds the best model object, the best hyperparameters, and evaluation scores for each targeted label.\n",
        "    \"\"\"\n",
        "\n",
        "    report = {}\n",
        "\n",
        "    print(\"Random Seed: \", seed)\n",
        "\n",
        "    for c in classes:\n",
        "\n",
        "        print(\"Class: \", c)\n",
        "        train_features = dataset_dict[c][\"train\"][0]\n",
        "        train_target = dataset_dict[c][\"train\"][1]\n",
        "        test_features = dataset_dict[c][\"test\"][0]\n",
        "        test_target = dataset_dict[c][\"test\"][1]\n",
        "\n",
        "        # Define the classifier\n",
        "        rf = RandomForestClassifier(random_state=seed)\n",
        "\n",
        "        # Define the hyperparameters and their values for the grid search\n",
        "        param_grid = {\n",
        "            'n_estimators': list(range(1, 401, 50)),\n",
        "            'criterion': ['gini', 'entropy'],  # Gini impurity or Shannon information gain\n",
        "            'min_samples_split': list(range(2, 101,20)),\n",
        "            'min_samples_leaf': list(range(1, 21,10)),\n",
        "            'max_depth': list(range(1, 51,10)),  # Specify the range when max_depth is used\n",
        "            'max_features': list(range(1, train_features.shape[1] + 1, 20))  # 1 to maximum number of features\n",
        "        }\n",
        "\n",
        "        # Create a cross validation object\n",
        "        cv = StratifiedKFold(n_splits=cv_n_splits, shuffle=True, random_state=seed)\n",
        "\n",
        "        # Create the GridSearchCV object\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=rf,\n",
        "            param_grid=param_grid,\n",
        "            scoring=make_scorer(balanced_accuracy_score),  # Choose an appropriate metric for your problem\n",
        "            cv=cv,\n",
        "            n_jobs=n_jobs,  # Use all available processors,\n",
        "            return_train_score=True\n",
        "        )\n",
        "\n",
        "        # Perform the grid search\n",
        "        grid_search.fit(train_features, train_target)\n",
        "\n",
        "        # Access cv_results_ attribute to get detailed results\n",
        "        cv_results = grid_search.cv_results_\n",
        "\n",
        "        # Print the best hyperparameters\n",
        "        print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "        # Get the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Evaluate the best model on test set\n",
        "        predictions = best_model.predict(test_features)\n",
        "\n",
        "        # Get classification report\n",
        "        class_report = classification_report(test_target, predictions)\n",
        "        # print(class_report)\n",
        "\n",
        "        # Get the balanced accuracy\n",
        "        balanced_accuracy = balanced_accuracy_score(test_target, predictions)\n",
        "        print(\"Test Score:\", balanced_accuracy)\n",
        "\n",
        "        # Create a confusion matrix\n",
        "        cm = confusion_matrix(test_target, predictions)\n",
        "        # print(f\"\\nConfusion matrix for {c}\\n\")\n",
        "        print(f\"True Positives: {cm[1, 1]}, True Negatives: {cm[0, 0]}, False Positives: {cm[0, 1]}, False Negatives: {cm[1, 0]}\")\n",
        "\n",
        "        # Calculate mean train score and mean test score\n",
        "        mean_train_score = cv_results['mean_train_score'][grid_search.best_index_]\n",
        "        mean_test_score = cv_results['mean_test_score'][grid_search.best_index_]\n",
        "\n",
        "        print(\"Mean Train Score:\", mean_train_score)\n",
        "        print(\"Mean Validation Score:\", mean_test_score)\n",
        "\n",
        "\n",
        "        report[c] = {\n",
        "            \"model\": best_model,\n",
        "            \"best_hyperparameters\": grid_search.best_params_,\n",
        "            \"test_score\": balanced_accuracy,\n",
        "            \"mean_train_score\": mean_train_score,\n",
        "            \"mean_validation_score\": mean_test_score,\n",
        "            \"confusion_matrix\": cm,\n",
        "            \"classification_report\": class_report,\n",
        "        }\n",
        "\n",
        "    return report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38haiL6cYiCT",
        "outputId": "8df3bf38-ca5e-4b8e-c0f2-1a0d817376f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Seed:  42\n",
            "Class:  HNSC\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 21, 'max_features': 61, 'min_samples_leaf': 1, 'min_samples_split': 42, 'n_estimators': 51}\n",
            "Test Score: 0.7922705314009661\n",
            "True Positives: 16, True Negatives: 48, False Positives: 6, False Negatives: 7\n",
            "Mean Train Score: 0.9402205662678312\n",
            "Mean Validation Score: 0.8451345102984448\n",
            "Class:  STAD\n",
            "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 11, 'max_features': 101, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 101}\n",
            "Test Score: 0.7722323049001816\n",
            "True Positives: 11, True Negatives: 56, False Positives: 2, False Negatives: 8\n",
            "Mean Train Score: 0.9746057203956162\n",
            "Mean Validation Score: 0.8339194139194139\n",
            "Class:  COAD\n",
            "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 11, 'max_features': 61, 'min_samples_leaf': 1, 'min_samples_split': 42, 'n_estimators': 101}\n",
            "Test Score: 0.9219600725952812\n",
            "True Positives: 18, True Negatives: 52, False Positives: 6, False Negatives: 1\n",
            "Mean Train Score: 0.9522089274700546\n",
            "Mean Validation Score: 0.9243656343656343\n",
            "Class:  ESCA\n",
            "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 11, 'max_features': 81, 'min_samples_leaf': 1, 'min_samples_split': 22, 'n_estimators': 1}\n",
            "Test Score: 0.5261437908496732\n",
            "True Positives: 1, True Negatives: 64, False Positives: 4, False Negatives: 8\n",
            "Mean Train Score: 0.78763999446966\n",
            "Mean Validation Score: 0.716555023923445\n",
            "Class:  READ\n",
            "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 11, 'max_features': 61, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1}\n",
            "Test Score: 0.5\n",
            "True Positives: 0, True Negatives: 70, False Positives: 0, False Negatives: 7\n",
            "Mean Train Score: 0.8273710666223785\n",
            "Mean Validation Score: 0.6775203435804701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/gbaldonado/miniforge3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/gbaldonado/miniforge3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/gbaldonado/miniforge3/envs/ml_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Run the perform_gridsearchcv with just one seed (will run faster)\n",
        "exp1_report = perform_gridsearchcv(exp1_datasets, classes, seed=seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyQaoCYEYiCT"
      },
      "source": [
        "**Checking for result variance**: The code in this block will run the `perform_gridsearchcv()` for 5 seeds to check for variance of the report. You don't need to run this, but keep in mind that checking statistical variance makes sure that\n",
        "\n",
        "```python\n",
        "# Run the perform_gridsearchcv with 5 seeds for variance (will run slower)\n",
        "random_seeds = [959, 699, 663, 73, 623]\n",
        "\n",
        "# Note: This optional cell will run for a long time depending on your computational resources.\n",
        "all_reports = []\n",
        "for s in random_seeds:\n",
        "    report = perform_gridsearchcv(exp1_datasets, classes, seed=s)\n",
        "    all_reports.append(report)\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB2LbRxUYiCT"
      },
      "source": [
        "It's good practice to export the findings of the experiment so that you can go back later and perform any analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezY1QpIGYiCT"
      },
      "outputs": [],
      "source": [
        "def best_hyperparameter_to_df(nested_dict, exp_name):\n",
        "    \"\"\"\n",
        "    Saves the best hyperparameters.\n",
        "\n",
        "    inputs:\n",
        "    nested_dict (dict): the report\n",
        "    exp_name (str): name of the experiment\n",
        "\n",
        "    output:\n",
        "    df (Dataframe): the table of the best hyperparameters and metrics\n",
        "    \"\"\"\n",
        "    path = \"./dataset/microbiome_preprocessed_files/\"\n",
        "    data = []\n",
        "\n",
        "    for key, value in nested_dict.items():\n",
        "        entry = {'label': key}\n",
        "        entry.update(value['best_hyperparameters'])\n",
        "        entry['test_score'] = value['test_score']\n",
        "        entry['mean_train_score'] = value['mean_train_score']\n",
        "        entry['mean_validation_score'] = value['mean_validation_score']\n",
        "        data.append(entry)\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    df.to_csv(path+f\"{exp_name}_best_hyperparam.csv\", index=False)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wM-1jy7YiCT",
        "outputId": "ed2013de-0618-424a-b3e2-46f2c2b1c2ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>criterion</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>max_features</th>\n",
              "      <th>min_samples_leaf</th>\n",
              "      <th>min_samples_split</th>\n",
              "      <th>n_estimators</th>\n",
              "      <th>test_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>mean_validation_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HNSC</td>\n",
              "      <td>gini</td>\n",
              "      <td>21</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>51</td>\n",
              "      <td>0.792271</td>\n",
              "      <td>0.940221</td>\n",
              "      <td>0.845135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>STAD</td>\n",
              "      <td>gini</td>\n",
              "      <td>11</td>\n",
              "      <td>101</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>101</td>\n",
              "      <td>0.772232</td>\n",
              "      <td>0.974606</td>\n",
              "      <td>0.833919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>COAD</td>\n",
              "      <td>gini</td>\n",
              "      <td>11</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>101</td>\n",
              "      <td>0.921960</td>\n",
              "      <td>0.952209</td>\n",
              "      <td>0.924366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ESCA</td>\n",
              "      <td>entropy</td>\n",
              "      <td>11</td>\n",
              "      <td>81</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0.526144</td>\n",
              "      <td>0.787640</td>\n",
              "      <td>0.716555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>READ</td>\n",
              "      <td>gini</td>\n",
              "      <td>11</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.827371</td>\n",
              "      <td>0.677520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label criterion  max_depth  max_features  min_samples_leaf  \\\n",
              "0  HNSC      gini         21            61                 1   \n",
              "1  STAD      gini         11           101                 1   \n",
              "2  COAD      gini         11            61                 1   \n",
              "3  ESCA   entropy         11            81                 1   \n",
              "4  READ      gini         11            61                 1   \n",
              "\n",
              "   min_samples_split  n_estimators  test_score  mean_train_score  \\\n",
              "0                 42            51    0.792271          0.940221   \n",
              "1                  2           101    0.772232          0.974606   \n",
              "2                 42           101    0.921960          0.952209   \n",
              "3                 22             1    0.526144          0.787640   \n",
              "4                  2             1    0.500000          0.827371   \n",
              "\n",
              "   mean_validation_score  \n",
              "0               0.845135  \n",
              "1               0.833919  \n",
              "2               0.924366  \n",
              "3               0.716555  \n",
              "4               0.677520  "
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparameter_to_df(exp1_report, \"exp1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb1TW_iFYiCT"
      },
      "source": [
        "## **5.) Results and Discussion**\n",
        "\n",
        "| Classification | Paper Test Accuracy | Experiment 1 Test Accuracy |\n",
        "|----------------|---------------------|----------------------------|\n",
        "| HNSC vs All    | 80.78               | 79.29                      |\n",
        "| STAD vs All    | 82.84               | 77.22                      |\n",
        "| COAD vs All    | 93.54               | 92.20                      |\n",
        "| ESCA vs All    | 61.37               | 52.61                      |\n",
        "| READ vs All    | 56.43               | 50.00                      |\n",
        "\n",
        "\n",
        "The table above highlights variations in test accuracy between the paper's reported results and this notebook's experiment 1 for each cancer type or class. It is clear there is a decrease in test accuracy across all classes, but this difference is expected given that for we used a distilled version of the hyperparameter grid when training our models. The magnitude of the difference in test accuracy varies, with some cancer types experiencing only minor deviations, while others more substantial difference.\n",
        "1. HNSC vs All, COAD vs All:\n",
        "* These are the top performers. The difference between experiment and paper (-1.49, -1.34) is relatively small, suggesting that the model's performance is reasonably consistent between the experiment and paper. Their top performance can be attributed to higher class distributions based on our exploratory data analysis (EDA) from notebook 1.\n",
        "2. STAD vs All:\n",
        "* The difference (-5.62) is noticeable. This is an interesting result because it is unexpected, given that STAD has the second highest class distribution based on our EDA.\n",
        "3. ESCA vs All and READ vs All:\n",
        "* The differences (-8.76, -6.43) are significant, and this can be attributed to the lower counts of samples belonging to ESCA and READ based on our EDA. In the first notebook, we hypothesized that ESCA and READ will perform the worst. After running the experiments, our hypothesis turns out to be correct!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bzgQfaHYiCT"
      },
      "source": [
        "## Task 2:\n",
        "\n",
        "Look back into the class distribution from our EDA in notebook 1. Discuss how the class distribution could play into effect on how the models performed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X337PThbYiCT"
      },
      "source": [
        "**Your answer**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuSS2huaYiCT"
      },
      "source": [
        "## Task 3:\n",
        "\n",
        "For extra practice, try removing or adding new hyperparameter values in the `param_grid` and rerun the experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0bwEt_GYiCT"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78ETeWWEYiCT"
      },
      "source": [
        "**Exporting**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Export the results to colab\n",
        "import json\n",
        "\n",
        "path = \"/content/drive/MyDrive/microbiome_dataset/microbiome_preprocessed_files/\"\n",
        "os.makedirs(path, exist_ok=True)\n",
        "\n",
        "with open(path + \"exp1_report.txt\", \"w\") as file:\n",
        "    json.dump(str(exp1_report), file, indent=4)"
      ],
      "metadata": {
        "id": "WsloF_XDZG6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5pGvGdZYiCT"
      },
      "outputs": [],
      "source": [
        "## Export the results locally\n",
        "import json\n",
        "\n",
        "path = \"./dataset/microbiome_preprocessed_files/\"\n",
        "os.makedirs(\"./dataset/microbiome_preprocessed_files/\", exist_ok=True)\n",
        "\n",
        "with open(path + \"exp1_report.txt\", \"w\") as file:\n",
        "    json.dump(str(exp1_report), file, indent=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uyn8H7IdYiCT"
      },
      "source": [
        "Thanks for making it this far! We have accomplished experiment 1, which will serve as our baseline for our other experiments. In experiment 2, we will explore if we can improve our performance by adding additional features using feature engineering."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}